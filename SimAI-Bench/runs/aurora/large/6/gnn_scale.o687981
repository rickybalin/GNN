Loaded modules:

Currently Loaded Modules:
  1) libfabric/1.15.2.0                     6) gmp/6.2.1-pcxzkau                11) mpich-config/collective-tuning/1024
  2) cray-pals/1.3.3                        7) mpfr/4.2.0-w7v7yjv               12) oneapi/release/2024.1
  3) cray-libpals/1.3.3                     8) mpc/1.3.1-dfagrna                13) frameworks/2024.1
  4) intel_compute_runtime/release/803.29   9) gcc/12.2.0
  5) spack-pe-gcc/0.7.0-24.086.0           10) mpich/icc-all-pmix-gpu/20231026

 


Torch version: 2.1.0.post0+cxx11.abi
IPEX version: 2.1.20+xpu
Torch Geometric version: 2.5.3

Number of nodes: 1
Number of ranks per node: 12
Number of total ranks: 12

Setting oneCCL bindings for 12 ranks per node

Running script /lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/SimAI-Bench/main.py
with arguments --device=xpu --iterations=100 --problem_size=large
Wed 26 Jun 2024 02:42:06 PM UTC
cpubind:list x4704c6s7b0n0 pid 28489 rank 0 0: mask 0x1c
cpubind:list x4704c6s7b0n0 pid 28490 rank 1 1: mask 0x1c00
cpubind:list x4704c6s7b0n0 pid 28491 rank 2 2: mask 0x1c0000
cpubind:list x4704c6s7b0n0 pid 28492 rank 3 3: mask 0x1c000000
cpubind:list x4704c6s7b0n0 pid 28493 rank 4 4: mask 0x1c00000000
cpubind:list x4704c6s7b0n0 pid 28494 rank 5 5: mask 0x1c0000000000
cpubind:list x4704c6s7b0n0 pid 28495 rank 6 6: mask 0x1c0000000000000
cpubind:list x4704c6s7b0n0 pid 28496 rank 7 7: mask 0x1c000000000000000
cpubind:list x4704c6s7b0n0 pid 28497 rank 8 8: mask 0x1c00000000000000000
cpubind:list x4704c6s7b0n0 pid 28498 rank 9 9: mask 0x1c0000000000000000000
cpubind:list x4704c6s7b0n0 pid 28499 rank 10 10: mask 0x1c000000000000000000000
cpubind:list x4704c6s7b0n0 pid 28500 rank 11 11: mask 0x1c00000000000000000000000
Hello from rank 0/12, local rank 0 on x4704c6s7b0n0
Hello from rank 1/12, local rank 1 on x4704c6s7b0n0
Hello from rank 2/12, local rank 2 on x4704c6s7b0n0
Hello from rank 3/12, local rank 3 on x4704c6s7b0n0
Hello from rank 4/12, local rank 4 on x4704c6s7b0n0
Hello from rank 5/12, local rank 5 on x4704c6s7b0n0
Hello from rank 6/12, local rank 6 on x4704c6s7b0n0
Hello from rank 7/12, local rank 7 on x4704c6s7b0n0
Hello from rank 8/12, local rank 8 on x4704c6s7b0n0
Hello from rank 9/12, local rank 9 on x4704c6s7b0n0
Hello from rank 10/12, local rank 10 on x4704c6s7b0n0
Hello from rank 11/12, local rank 11 on x4704c6s7b0n0

Loaded data and model with 163491 parameters

2024:06:26-14:42:15:(28492) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:06:26-14:42:15:(28499) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:06:26-14:42:15:(28498) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:06:26-14:42:15:(28496) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:06:26-14:42:15:(28491) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:06:26-14:42:15:(28495) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
Running on device: xpu 

2024:06:26-14:42:15:(28489) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:06:26-14:42:15:(28500) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:06:26-14:42:15:(28497) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:06:26-14:42:15:(28494) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:06:26-14:42:15:(28493) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:06:26-14:42:15:(28490) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:06:26-14:42:16:(28489) |CCL_WARN| MPI was initialized externaly but with unexpected thread level: required 3, provided 0
2024:06:26-14:42:16:(28490) |CCL_WARN| MPI was initialized externaly but with unexpected thread level: required 3, provided 0
2024:06:26-14:42:16:(28491) |CCL_WARN| MPI was initialized externaly but with unexpected thread level: required 3, provided 0
2024:06:26-14:42:16:(28492) |CCL_WARN| MPI was initialized externaly but with unexpected thread level: required 3, provided 0
2024:06:26-14:42:16:(28493) |CCL_WARN| MPI was initialized externaly but with unexpected thread level: required 3, provided 0
2024:06:26-14:42:16:(28494) |CCL_WARN| MPI was initialized externaly but with unexpected thread level: required 3, provided 0
2024:06:26-14:42:16:(28495) |CCL_WARN| MPI was initialized externaly but with unexpected thread level: required 3, provided 0
2024:06:26-14:42:16:(28496) |CCL_WARN| MPI was initialized externaly but with unexpected thread level: required 3, provided 0
2024:06:26-14:42:16:(28497) |CCL_WARN| MPI was initialized externaly but with unexpected thread level: required 3, provided 0
2024:06:26-14:42:16:(28498) |CCL_WARN| MPI was initialized externaly but with unexpected thread level: required 3, provided 0
2024:06:26-14:42:16:(28499) |CCL_WARN| MPI was initialized externaly but with unexpected thread level: required 3, provided 0
2024:06:26-14:42:16:(28500) |CCL_WARN| MPI was initialized externaly but with unexpected thread level: required 3, provided 0

Starting training loop ... 
[0]: avg_loss = 3.813912e-02
[1]: avg_loss = 3.597362e-02
[2]: avg_loss = 3.411888e-02
[3]: avg_loss = 3.227879e-02
[4]: avg_loss = 3.050134e-02
[5]: avg_loss = 2.880268e-02
[6]: avg_loss = 2.736332e-02
[7]: avg_loss = 2.595912e-02
[8]: avg_loss = 2.446039e-02
[9]: avg_loss = 2.297994e-02
[10]: avg_loss = 2.152361e-02
[11]: avg_loss = 2.002314e-02
[12]: avg_loss = 1.875398e-02
[13]: avg_loss = 1.776052e-02
[14]: avg_loss = 1.688502e-02
[15]: avg_loss = 1.604979e-02
[16]: avg_loss = 1.534393e-02
[17]: avg_loss = 1.459083e-02
[18]: avg_loss = 1.394496e-02
[19]: avg_loss = 1.325877e-02
[20]: avg_loss = 1.246031e-02
[21]: avg_loss = 1.172164e-02
[22]: avg_loss = 1.123699e-02
[23]: avg_loss = 1.084738e-02
[24]: avg_loss = 1.060390e-02
[25]: avg_loss = 1.056367e-02
[26]: avg_loss = 1.062913e-02
[27]: avg_loss = 1.068401e-02
[28]: avg_loss = 1.063890e-02
[29]: avg_loss = 1.056602e-02
[30]: avg_loss = 1.049406e-02
[31]: avg_loss = 1.043487e-02
[32]: avg_loss = 1.041061e-02
[33]: avg_loss = 1.042415e-02
[34]: avg_loss = 1.046026e-02
[35]: avg_loss = 1.048306e-02
[36]: avg_loss = 1.047238e-02
[37]: avg_loss = 1.044420e-02
[38]: avg_loss = 1.041467e-02
[39]: avg_loss = 1.039337e-02
[40]: avg_loss = 1.038873e-02
[41]: avg_loss = 1.039329e-02
[42]: avg_loss = 1.040087e-02
[43]: avg_loss = 1.040708e-02
[44]: avg_loss = 1.040990e-02
[45]: avg_loss = 1.040927e-02
[46]: avg_loss = 1.040522e-02
[47]: avg_loss = 1.039864e-02
[48]: avg_loss = 1.039181e-02
[49]: avg_loss = 1.038738e-02
[50]: avg_loss = 1.038670e-02
[51]: avg_loss = 1.038876e-02
[52]: avg_loss = 1.039136e-02
[53]: avg_loss = 1.039281e-02
[54]: avg_loss = 1.039266e-02
[55]: avg_loss = 1.039144e-02
[56]: avg_loss = 1.038971e-02
[57]: avg_loss = 1.038770e-02
[58]: avg_loss = 1.038560e-02
[59]: avg_loss = 1.038388e-02
[60]: avg_loss = 1.038302e-02
[61]: avg_loss = 1.038305e-02
[62]: avg_loss = 1.038343e-02
[63]: avg_loss = 1.038346e-02
[64]: avg_loss = 1.038275e-02
[65]: avg_loss = 1.038135e-02
[66]: avg_loss = 1.037952e-02
[67]: avg_loss = 1.037745e-02
[68]: avg_loss = 1.037532e-02
[69]: avg_loss = 1.037328e-02
[70]: avg_loss = 1.037142e-02
[71]: avg_loss = 1.036952e-02
[72]: avg_loss = 1.036556e-02
[73]: avg_loss = 1.036249e-02
[74]: avg_loss = 1.035821e-02
[75]: avg_loss = 1.035288e-02
[76]: avg_loss = 1.034672e-02
[77]: avg_loss = 1.034020e-02
[78]: avg_loss = 1.033159e-02
[79]: avg_loss = 1.032211e-02
[80]: avg_loss = 1.031077e-02
[81]: avg_loss = 1.029713e-02
[82]: avg_loss = 1.028027e-02
[83]: avg_loss = 1.025977e-02
[84]: avg_loss = 1.023564e-02
[85]: avg_loss = 1.020742e-02
[86]: avg_loss = 1.017441e-02
[87]: avg_loss = 1.013534e-02
[88]: avg_loss = 1.008864e-02
[89]: avg_loss = 1.003306e-02
[90]: avg_loss = 9.972396e-03
[91]: avg_loss = 9.901463e-03
[92]: avg_loss = 9.818822e-03
[93]: avg_loss = 9.715295e-03
[94]: avg_loss = 9.589152e-03
[95]: avg_loss = 9.438491e-03
[96]: avg_loss = 9.239207e-03
[97]: avg_loss = 9.017909e-03
[98]: avg_loss = 8.755060e-03
[99]: avg_loss = 8.446548e-03

Summary of performance data:
training_loop [s] : min = 8.904568e+01 , max = 8.904701e+01 , avg = 8.904626e+01 , std = 3.066077e-04 
train_tot [s] : min = 8.632824e+01 , max = 8.642373e+01 , avg = 8.639800e+01 , std = 2.491653e-02 
train_iter [s] : min = 8.692460e-01 , max = 8.966477e-01 , avg = 8.727071e-01 , std = 2.236644e-03 
throughput_iter [s] : min = 1.115265e+06 , max = 1.150422e+06 , avg = 1.145867e+06 , std = 2.903708e+03 
forward_pass [s] : min = 1.738596e-02 , max = 4.209100e-02 , avg = 1.890911e-02 , std = 1.470088e-03 
loss [s] : min = 1.987290e-04 , max = 4.216580e-04 , avg = 2.322490e-04 , std = 2.579117e-05 
backward_pass [s] : min = 8.437334e-01 , max = 8.616755e-01 , avg = 8.476940e-01 , std = 1.864318e-03 
optimizer_step [s] : min = 4.961635e-03 , max = 6.528083e-03 , avg = 5.402153e-03 , std = 2.459782e-04 
[WARNING] yaksa: 2 leaked handle pool objects
[WARNING] yaksa: 2 leaked handle pool objects
[WARNING] yaksa: 2 leaked handle pool objects
[WARNING] yaksa: 2 leaked handle pool objects
[WARNING] yaksa: 2 leaked handle pool objects
[WARNING] yaksa: 2 leaked handle pool objects
[WARNING] yaksa: 2 leaked handle pool objects
[WARNING] yaksa: 2 leaked handle pool objects
[WARNING] yaksa: 2 leaked handle pool objects
[WARNING] yaksa: 2 leaked handle pool objects
[WARNING] yaksa: 2 leaked handle pool objects
Average parallel training throughout [nodes/s] : 1.375041e+07
[WARNING] yaksa: 2 leaked handle pool objects
2024:06:26-14:43:45:(28489) |CCL_WARN| MPI_Finalize has been called before CCL finalization
Wed 26 Jun 2024 02:43:46 PM UTC
