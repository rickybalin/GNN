
The following have been reloaded with a version change:
  1) intel_compute_runtime/release/821.36 => intel_compute_runtime/release/803.29
  2) oneapi/eng-compiler/2024.04.15.002 => oneapi/release/2024.1

Loaded modules:

Currently Loaded Modules:
  1) mpich/icc-all-pmix-gpu/20231026       6) spack-pe-gcc/0.7.0-24.086.0  11) intel_compute_runtime/release/803.29
  2) mpich-config/collective-tuning/1024   7) gmp/6.2.1-pcxzkau            12) oneapi/release/2024.1
  3) libfabric/1.15.2.0                    8) mpfr/4.2.0-w7v7yjv           13) frameworks/2024.1
  4) cray-pals/1.3.3                       9) mpc/1.3.1-dfagrna
  5) cray-libpals/1.3.3                   10) gcc/12.2.0

 


Torch version: 2.1.0.post0+cxx11.abi
IPEX version: 2.1.20+xpu
Torch Geometric version: 2.5.3

Number of nodes: 1
Number of ranks per node: 1
Number of total ranks: 1

Not setting oneCCL bindings

Running script /lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/SimAI-Bench/main.py
with arguments --device=xpu --iterations=150 --problem_size=large
Thu 01 Aug 2024 06:18:39 PM UTC
cpubind:list x4315c6s0b0n0 pid 183538 rank 0 0: mask 0x1c
Hello from rank 0/1, local rank 0 on x4315c6s0b0n0

Loaded data and model with 163491 parameters

Running on device: xpu 


Starting training loop ... 
[0]: avg_loss = 2.916167e-02
[1]: avg_loss = 2.891712e-02
[2]: avg_loss = 2.867183e-02
[3]: avg_loss = 2.842125e-02
[4]: avg_loss = 2.816931e-02
[5]: avg_loss = 2.791416e-02
[6]: avg_loss = 2.765857e-02
[7]: avg_loss = 2.740142e-02
[8]: avg_loss = 2.714190e-02
[9]: avg_loss = 2.688111e-02
[10]: avg_loss = 2.661894e-02
[11]: avg_loss = 2.635556e-02
[12]: avg_loss = 2.609211e-02
[13]: avg_loss = 2.582767e-02
[14]: avg_loss = 2.556220e-02
[15]: avg_loss = 2.531102e-02
[16]: avg_loss = 2.507031e-02
[17]: avg_loss = 2.482914e-02
[18]: avg_loss = 2.458962e-02
[19]: avg_loss = 2.431647e-02
[20]: avg_loss = 2.402902e-02
[21]: avg_loss = 2.373508e-02
[22]: avg_loss = 2.346340e-02
[23]: avg_loss = 2.319221e-02
[24]: avg_loss = 2.292078e-02
[25]: avg_loss = 2.264610e-02
[26]: avg_loss = 2.236842e-02
[27]: avg_loss = 2.208751e-02
[28]: avg_loss = 2.180505e-02
[29]: avg_loss = 2.151764e-02
[30]: avg_loss = 2.123295e-02
[31]: avg_loss = 2.094841e-02
[32]: avg_loss = 2.067878e-02
[33]: avg_loss = 2.041795e-02
[34]: avg_loss = 2.018026e-02
[35]: avg_loss = 1.994671e-02
[36]: avg_loss = 1.971287e-02
[37]: avg_loss = 1.947865e-02
[38]: avg_loss = 1.924315e-02
[39]: avg_loss = 1.900648e-02
[40]: avg_loss = 1.876862e-02
[41]: avg_loss = 1.853162e-02
[42]: avg_loss = 1.829391e-02
[43]: avg_loss = 1.805570e-02
[44]: avg_loss = 1.781670e-02
[45]: avg_loss = 1.757560e-02
[46]: avg_loss = 1.733381e-02
[47]: avg_loss = 1.709015e-02
[48]: avg_loss = 1.683852e-02
[49]: avg_loss = 1.659101e-02
[50]: avg_loss = 1.634065e-02
[51]: avg_loss = 1.608858e-02
[52]: avg_loss = 1.583803e-02
[53]: avg_loss = 1.559259e-02
[54]: avg_loss = 1.535311e-02
[55]: avg_loss = 1.511556e-02
[56]: avg_loss = 1.487975e-02
[57]: avg_loss = 1.464645e-02
[58]: avg_loss = 1.441691e-02
[59]: avg_loss = 1.419133e-02
[60]: avg_loss = 1.396878e-02
[61]: avg_loss = 1.374871e-02
[62]: avg_loss = 1.353288e-02
[63]: avg_loss = 1.332068e-02
[64]: avg_loss = 1.311247e-02
[65]: avg_loss = 1.290851e-02
[66]: avg_loss = 1.271046e-02
[67]: avg_loss = 1.251806e-02
[68]: avg_loss = 1.234448e-02
[69]: avg_loss = 1.219095e-02
[70]: avg_loss = 1.204357e-02
[71]: avg_loss = 1.190323e-02
[72]: avg_loss = 1.176955e-02
[73]: avg_loss = 1.164215e-02
[74]: avg_loss = 1.152188e-02
[75]: avg_loss = 1.140903e-02
[76]: avg_loss = 1.130309e-02
[77]: avg_loss = 1.120748e-02
[78]: avg_loss = 1.111791e-02
[79]: avg_loss = 1.103418e-02
[80]: avg_loss = 1.095609e-02
[81]: avg_loss = 1.088346e-02
[82]: avg_loss = 1.081604e-02
[83]: avg_loss = 1.075414e-02
[84]: avg_loss = 1.069893e-02
[85]: avg_loss = 1.064889e-02
[86]: avg_loss = 1.060283e-02
[87]: avg_loss = 1.055586e-02
[88]: avg_loss = 1.051186e-02
[89]: avg_loss = 1.047105e-02
[90]: avg_loss = 1.043389e-02
[91]: avg_loss = 1.039985e-02
[92]: avg_loss = 1.037053e-02
[93]: avg_loss = 1.034505e-02
[94]: avg_loss = 1.032255e-02
[95]: avg_loss = 1.030337e-02
[96]: avg_loss = 1.028620e-02
[97]: avg_loss = 1.027093e-02
[98]: avg_loss = 1.025753e-02
[99]: avg_loss = 1.024590e-02
[100]: avg_loss = 1.023601e-02
[101]: avg_loss = 1.022766e-02
[102]: avg_loss = 1.022145e-02
[103]: avg_loss = 1.021685e-02
[104]: avg_loss = 1.021296e-02
[105]: avg_loss = 1.020972e-02
[106]: avg_loss = 1.020704e-02
[107]: avg_loss = 1.020487e-02
[108]: avg_loss = 1.020314e-02
[109]: avg_loss = 1.020179e-02
[110]: avg_loss = 1.020079e-02
[111]: avg_loss = 1.020004e-02
[112]: avg_loss = 1.019952e-02
[113]: avg_loss = 1.019917e-02
[114]: avg_loss = 1.019895e-02
[115]: avg_loss = 1.019883e-02
[116]: avg_loss = 1.019878e-02
[117]: avg_loss = 1.019878e-02
[118]: avg_loss = 1.019879e-02
[119]: avg_loss = 1.019882e-02
[120]: avg_loss = 1.019884e-02
[121]: avg_loss = 1.019886e-02
[122]: avg_loss = 1.019885e-02
[123]: avg_loss = 1.019883e-02
[124]: avg_loss = 1.019878e-02
[125]: avg_loss = 1.019871e-02
[126]: avg_loss = 1.019863e-02
[127]: avg_loss = 1.019853e-02
[128]: avg_loss = 1.019842e-02
[129]: avg_loss = 1.019830e-02
[130]: avg_loss = 1.019817e-02
[131]: avg_loss = 1.019804e-02
[132]: avg_loss = 1.019791e-02
[133]: avg_loss = 1.019778e-02
[134]: avg_loss = 1.019765e-02
[135]: avg_loss = 1.019752e-02
[136]: avg_loss = 1.019737e-02
[137]: avg_loss = 1.019725e-02
[138]: avg_loss = 1.019715e-02
[139]: avg_loss = 1.019705e-02
[140]: avg_loss = 1.019695e-02
[141]: avg_loss = 1.019686e-02
[142]: avg_loss = 1.019678e-02
[143]: avg_loss = 1.019671e-02
[144]: avg_loss = 1.019664e-02
[145]: avg_loss = 1.019657e-02
[146]: avg_loss = 1.019651e-02
[147]: avg_loss = 1.019645e-02
[148]: avg_loss = 1.019639e-02
[149]: avg_loss = 1.019633e-02

Performance data averaged over 1 ranks and 148 iterations:
training_loop [s] : min = 1.254863e+02 , max = 1.254863e+02 , avg = 1.254863e+02 , std = 0.000000e+00 
train_tot [s] : min = 1.232054e+02 , max = 1.232054e+02 , avg = 1.232054e+02 , std = 0.000000e+00 
train_iter [s] : min = 8.299922e-01 , max = 8.343505e-01 , avg = 8.324691e-01 , std = 7.616835e-04 
throughput_iter [s] : min = 1.198537e+06 , max = 1.204831e+06 , avg = 1.201247e+06 , std = 1.099433e+03 
forward_pass [s] : min = 1.721468e-02 , max = 2.013561e-02 , avg = 1.793804e-02 , std = 5.819185e-04 
loss [s] : min = 1.879780e-04 , max = 2.585000e-04 , avg = 1.998028e-04 , std = 1.513438e-05 
backward_pass [s] : min = 3.731446e-02 , max = 4.074746e-02 , avg = 3.823990e-02 , std = 7.110407e-04 
optimizer_step [s] : min = 6.655934e-03 , max = 7.096851e-03 , avg = 6.807252e-03 , std = 8.484577e-05 
collectives [s] : min = 2.379529e-07 , max = 4.430767e-07 , avg = 2.995799e-07 , std = 3.128131e-08 
Average parallel training throughout [nodes/s] : 1.201247e+06
Thu 01 Aug 2024 06:20:56 PM UTC
