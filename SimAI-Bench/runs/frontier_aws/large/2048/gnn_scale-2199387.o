Loaded modules:

Torch version: 2.2.2+rocm5.7
NCCL version: (2, 17, 1)
cuDNN version: 2020000
Torch Geometric version: 2.5.3

Number of nodes: 512
Number of ML ranks per node: 8
Number of ML total ranks: 4096

Running script /lustre/orion/csc613/proj-shared/balin/Nek/GNN/GNN/SimAI-Bench/main.py
with arguments --device=cuda --iterations=150 --problem_size=large --master_addr=10.128.1.152 --master_port=3442

Tue 06 Aug 2024 02:53:33 PM EDT

Loaded data and model with 163491 parameters

Running on device: cuda 


Starting training loop ... 
[0]: avg_loss = 2.677076e-02
[1]: avg_loss = 1.143638e+10
[2]: avg_loss = 2.542788e+07
[3]: avg_loss = 7.098497e+06
[4]: avg_loss = 2.871263e+06
[5]: avg_loss = 2.981566e+11
[6]: avg_loss = 2.400285e+07
[7]: avg_loss = 1.383983e+02
[8]: avg_loss = 9.114295e+03
[9]: avg_loss = 1.470293e+04
[10]: avg_loss = 4.723232e+06
[11]: avg_loss = 3.080489e+06
[12]: avg_loss = 2.694883e+01
[13]: avg_loss = 3.408642e+01
[14]: avg_loss = 2.254291e+10
[15]: avg_loss = 2.914994e+10
[16]: avg_loss = 1.113582e+08
[17]: avg_loss = 1.035250e+05
[18]: avg_loss = 1.183614e+05
[19]: avg_loss = 9.003606e+04
[20]: avg_loss = 4.479978e+04
[21]: avg_loss = 1.850542e+04
[22]: avg_loss = 1.393431e+04
[23]: avg_loss = 1.151359e+04
[24]: avg_loss = 8.036399e+03
[25]: avg_loss = 6.973104e+05
[26]: avg_loss = 2.026639e+05
[27]: avg_loss = 5.165886e+00
[28]: avg_loss = 3.440655e+00
[29]: avg_loss = 3.611247e+00
[30]: avg_loss = 3.770307e+00
[31]: avg_loss = 3.918241e+00
[32]: avg_loss = 4.055473e+00
[33]: avg_loss = 4.182522e+00
[34]: avg_loss = 4.299949e+00
[35]: avg_loss = 4.408358e+00
[36]: avg_loss = 4.508233e+00
[37]: avg_loss = 4.600111e+00
[38]: avg_loss = 4.684606e+00
[39]: avg_loss = 4.762159e+00
[40]: avg_loss = 4.833335e+00
[41]: avg_loss = 4.898543e+00
[42]: avg_loss = 4.958263e+00
[43]: avg_loss = 5.012889e+00
[44]: avg_loss = 5.062849e+00
[45]: avg_loss = 5.108465e+00
[46]: avg_loss = 5.150134e+00
[47]: avg_loss = 5.188202e+00
[48]: avg_loss = 5.222886e+00
[49]: avg_loss = 5.254500e+00
[50]: avg_loss = 5.283343e+00
[51]: avg_loss = 5.309631e+00
[52]: avg_loss = 5.333517e+00
[53]: avg_loss = 5.355319e+00
[54]: avg_loss = 5.375092e+00
[55]: avg_loss = 5.393126e+00
[56]: avg_loss = 5.409455e+00
[57]: avg_loss = 5.424383e+00
[58]: avg_loss = 5.437907e+00
[59]: avg_loss = 5.450153e+00
[60]: avg_loss = 5.461300e+00
[61]: avg_loss = 5.471517e+00
[62]: avg_loss = 5.480633e+00
[63]: avg_loss = 5.489032e+00
[64]: avg_loss = 5.496608e+00
[65]: avg_loss = 5.503432e+00
[66]: avg_loss = 5.509658e+00
[67]: avg_loss = 5.515286e+00
[68]: avg_loss = 5.520389e+00
[69]: avg_loss = 5.525082e+00
[70]: avg_loss = 5.529238e+00
[71]: avg_loss = 5.533026e+00
[72]: avg_loss = 5.536547e+00
[73]: avg_loss = 5.539560e+00
[74]: avg_loss = 5.542436e+00
[75]: avg_loss = 5.544920e+00
[76]: avg_loss = 5.547183e+00
[77]: avg_loss = 5.549282e+00
[78]: avg_loss = 5.551134e+00
[79]: avg_loss = 5.552824e+00
[80]: avg_loss = 5.554402e+00
[81]: avg_loss = 5.555830e+00
[82]: avg_loss = 5.557004e+00
[83]: avg_loss = 5.558131e+00
[84]: avg_loss = 5.559149e+00
[85]: avg_loss = 5.560031e+00
[86]: avg_loss = 5.560816e+00
[87]: avg_loss = 5.561598e+00
[88]: avg_loss = 5.562195e+00
[89]: avg_loss = 5.562779e+00
[90]: avg_loss = 5.563362e+00
[91]: avg_loss = 5.563797e+00
[92]: avg_loss = 5.564153e+00
[93]: avg_loss = 5.564510e+00
[94]: avg_loss = 5.564865e+00
[95]: avg_loss = 5.565189e+00
[96]: avg_loss = 5.565448e+00
[97]: avg_loss = 5.565649e+00
[98]: avg_loss = 5.565837e+00
[99]: avg_loss = 5.565976e+00
[100]: avg_loss = 5.566097e+00
[101]: avg_loss = 5.566199e+00
[102]: avg_loss = 5.566305e+00
[103]: avg_loss = 5.566374e+00
[104]: avg_loss = 5.566455e+00
[105]: avg_loss = 5.566521e+00
[106]: avg_loss = 5.566543e+00
[107]: avg_loss = 5.566584e+00
[108]: avg_loss = 5.566609e+00
[109]: avg_loss = 5.566611e+00
[110]: avg_loss = 5.566611e+00
[111]: avg_loss = 5.566609e+00
[112]: avg_loss = 5.566583e+00
[113]: avg_loss = 5.566544e+00
[114]: avg_loss = 5.566526e+00
[115]: avg_loss = 5.566494e+00
[116]: avg_loss = 5.566431e+00
[117]: avg_loss = 5.566387e+00
[118]: avg_loss = 5.566341e+00
[119]: avg_loss = 5.566294e+00
[120]: avg_loss = 5.566233e+00
[121]: avg_loss = 5.566168e+00
[122]: avg_loss = 5.566118e+00
[123]: avg_loss = 5.566062e+00
[124]: avg_loss = 5.566004e+00
[125]: avg_loss = 5.565938e+00
[126]: avg_loss = 5.565890e+00
[127]: avg_loss = 5.565825e+00
[128]: avg_loss = 5.565752e+00
[129]: avg_loss = 5.565674e+00
[130]: avg_loss = 5.565596e+00
[131]: avg_loss = 5.565534e+00
[132]: avg_loss = 5.565449e+00
[133]: avg_loss = 5.565369e+00
[134]: avg_loss = 5.565286e+00
[135]: avg_loss = 5.565197e+00
[136]: avg_loss = 5.565091e+00
[137]: avg_loss = 5.565011e+00
[138]: avg_loss = 5.564888e+00
[139]: avg_loss = 5.564814e+00
[140]: avg_loss = 5.564702e+00
[141]: avg_loss = 5.564621e+00
[142]: avg_loss = 5.564504e+00
[143]: avg_loss = 5.564424e+00
[144]: avg_loss = 5.564314e+00
[145]: avg_loss = 5.564234e+00
[146]: avg_loss = 5.564147e+00
[147]: avg_loss = 5.564060e+00
[148]: avg_loss = 5.563998e+00
[149]: avg_loss = 5.563904e+00

Performance data averaged over 4096 ranks and 148 iterations:
training_loop [s] : min = 1.653666e+02 , max = 1.716306e+02 , avg = 1.700643e+02 , std = 5.145274e-01 
train_tot [s] : min = 1.586618e+02 , max = 1.593308e+02 , avg = 1.590001e+02 , std = 1.758501e-01 
train_iter [s] : min = 7.768065e-01 , max = 1.636362e+00 , avg = 1.074325e+00 , std = 1.469249e-01 
throughput_iter [s] : min = 6.111118e+05 , max = 1.287322e+06 , avg = 9.469635e+05 , std = 1.195485e+05 
forward_pass [s] : min = 1.121157e-02 , max = 1.592096e+00 , avg = 3.288749e-01 , std = 2.482554e-01 
loss [s] : min = 1.683560e-04 , max = 5.314740e-04 , avg = 2.041536e-04 , std = 2.713758e-05 
backward_pass [s] : min = 2.301935e-02 , max = 8.880476e-01 , avg = 5.942769e-01 , std = 1.758573e-01 
optimizer_step [s] : min = 3.092775e-03 , max = 4.011096e-01 , avg = 1.503216e-01 , std = 1.631985e-01 
collectives [s] : min = 8.863100e-05 , max = 2.865240e-04 , avg = 1.184037e-04 , std = 1.312467e-05 
Average parallel training throughout [nodes/s] : 3.878763e+09
Tue 06 Aug 2024 03:00:25 PM EDT
