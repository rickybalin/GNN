
The following have been reloaded with a version change:
  1) intel_compute_runtime/release/821.36 => intel_compute_runtime/release/803.29     2) oneapi/eng-compiler/2024.04.15.002 => oneapi/release/2024.1

Loaded modules:

Currently Loaded Modules:
  1) mpich/icc-all-pmix-gpu/20231026       5) cray-libpals/1.3.3            9) mpc/1.3.1-dfagrna                     13) frameworks/2024.1
  2) mpich-config/collective-tuning/1024   6) spack-pe-gcc/0.7.0-24.086.0  10) gcc/12.2.0
  3) libfabric/1.15.2.0                    7) gmp/6.2.1-pcxzkau            11) intel_compute_runtime/release/803.29
  4) cray-pals/1.3.3                       8) mpfr/4.2.0-w7v7yjv           12) oneapi/release/2024.1

 


Torch version: 2.1.0.post0+cxx11.abi
IPEX version: 2.1.20+xpu
Torch Geometric version: 2.5.3

Number of nodes: 2
Number of ML ranks per node: 12
Number of ML total ranks: 24

Setting oneCCL bindings for 12 ranks per node

Running script /flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py
with arguments backend=ccl halo_swap_mode=all_to_all_opt gnn_outputs_path=/flare/Aurora_deployment/balin/Nek/GNN/weak_scale_data/500k_aurora/24/gnn_outputs_poly_5/

Tue 09 Jul 2024 09:07:42 PM UTC
[2024-07-09 21:07:51,778][__main__][INFO] - Hello from rank 0/24, local rank 0, on device xpu:0 out of 12.
[2024-07-09 21:07:51,778][__main__][INFO] - Hello from rank 1/24, local rank 1, on device xpu:1 out of 12.
[2024-07-09 21:07:51,778][__main__][INFO] - Hello from rank 3/24, local rank 3, on device xpu:3 out of 12.
[2024-07-09 21:07:51,778][__main__][INFO] - Hello from rank 4/24, local rank 4, on device xpu:4 out of 12.
[2024-07-09 21:07:51,778][__main__][INFO] - Hello from rank 8/24, local rank 8, on device xpu:8 out of 12.
[2024-07-09 21:07:51,778][__main__][INFO] - Hello from rank 9/24, local rank 9, on device xpu:9 out of 12.
[2024-07-09 21:07:51,778][__main__][INFO] - Hello from rank 11/24, local rank 11, on device xpu:11 out of 12.
[2024-07-09 21:07:51,778][__main__][INFO] - Hello from rank 2/24, local rank 2, on device xpu:2 out of 12.
[2024-07-09 21:07:51,778][__main__][INFO] - Hello from rank 5/24, local rank 5, on device xpu:5 out of 12.
[2024-07-09 21:07:51,778][__main__][INFO] - Hello from rank 6/24, local rank 6, on device xpu:6 out of 12.
[2024-07-09 21:07:51,778][__main__][INFO] - Hello from rank 10/24, local rank 10, on device xpu:10 out of 12.
[2024-07-09 21:07:51,780][__main__][INFO] - Hello from rank 7/24, local rank 7, on device xpu:7 out of 12.
[2024-07-09 21:07:51,973][__main__][INFO] - [RANK 1]: Loading positions and global node index
[2024-07-09 21:07:51,973][__main__][INFO] - [RANK 4]: Loading positions and global node index
[2024-07-09 21:07:51,973][__main__][INFO] - [RANK 5]: Loading positions and global node index
[2024-07-09 21:07:51,973][__main__][INFO] - [RANK 7]: Loading positions and global node index
[2024-07-09 21:07:51,973][__main__][INFO] - [RANK 9]: Loading positions and global node index
[2024-07-09 21:07:51,973][__main__][INFO] - [RANK 2]: Loading positions and global node index
[2024-07-09 21:07:52,001][__main__][INFO] - [RANK 9]: Loading edge index
[2024-07-09 21:07:52,001][__main__][INFO] - [RANK 1]: Loading edge index
[2024-07-09 21:07:52,001][__main__][INFO] - [RANK 7]: Loading edge index
[2024-07-09 21:07:52,001][__main__][INFO] - [RANK 2]: Loading edge index
[2024-07-09 21:07:52,002][__main__][INFO] - [RANK 5]: Loading edge index
[2024-07-09 21:07:52,004][__main__][INFO] - [RANK 10]: Loading positions and global node index
[2024-07-09 21:07:52,004][__main__][INFO] - [RANK 6]: Loading positions and global node index
[2024-07-09 21:07:52,012][__main__][INFO] - [RANK 4]: Loading edge index
[2024-07-09 21:07:52,012][__main__][INFO] - [RANK 8]: Loading positions and global node index
[2024-07-09 21:07:52,015][__main__][INFO] - [RANK 11]: Loading positions and global node index
[2024-07-09 21:07:52,016][__main__][INFO] - [RANK 3]: Loading positions and global node index
[2024-07-09 21:07:52,033][__main__][INFO] - [RANK 6]: Loading edge index
[2024-07-09 21:07:52,041][__main__][INFO] - [RANK 10]: Loading edge index
[2024-07-09 21:07:52,044][__main__][INFO] - [RANK 11]: Loading edge index
[2024-07-09 21:07:52,045][__main__][INFO] - [RANK 8]: Loading edge index
[2024-07-09 21:07:52,055][__main__][INFO] - [RANK 3]: Loading edge index
[2024-07-09 21:07:52,093][__main__][INFO] - [RANK 7]: Loading local unique mask
[2024-07-09 21:07:52,093][__main__][INFO] - [RANK 1]: Loading local unique mask
[2024-07-09 21:07:52,093][__main__][INFO] - [RANK 9]: Loading local unique mask
[2024-07-09 21:07:52,095][__main__][INFO] - [RANK 5]: Loading local unique mask
[2024-07-09 21:07:52,097][__main__][INFO] - [RANK 2]: Loading local unique mask
[2024-07-09 21:07:52,101][__main__][INFO] - [RANK 7]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,102][__main__][INFO] - [RANK 9]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,102][__main__][INFO] - [RANK 1]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,103][__main__][INFO] - [RANK 5]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,105][__main__][INFO] - [RANK 4]: Loading local unique mask
[2024-07-09 21:07:52,106][__main__][INFO] - [RANK 2]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,112][__main__][INFO] - [RANK 4]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,128][__main__][INFO] - [RANK 6]: Loading local unique mask
[2024-07-09 21:07:52,134][__main__][INFO] - [RANK 10]: Loading local unique mask
[2024-07-09 21:07:52,137][__main__][INFO] - [RANK 6]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,138][__main__][INFO] - [RANK 11]: Loading local unique mask
[2024-07-09 21:07:52,138][__main__][INFO] - Hello from rank 12/24, local rank 0, on device xpu:0 out of 12.
[2024-07-09 21:07:52,138][__main__][INFO] - Hello from rank 15/24, local rank 3, on device xpu:3 out of 12.
[2024-07-09 21:07:52,138][__main__][INFO] - Hello from rank 16/24, local rank 4, on device xpu:4 out of 12.
[2024-07-09 21:07:52,138][__main__][INFO] - Hello from rank 19/24, local rank 7, on device xpu:7 out of 12.
[2024-07-09 21:07:52,138][__main__][INFO] - Hello from rank 20/24, local rank 8, on device xpu:8 out of 12.
[2024-07-09 21:07:52,138][__main__][INFO] - Hello from rank 22/24, local rank 10, on device xpu:10 out of 12.
[2024-07-09 21:07:52,138][__main__][INFO] - Hello from rank 23/24, local rank 11, on device xpu:11 out of 12.
[2024-07-09 21:07:52,138][__main__][INFO] - Hello from rank 14/24, local rank 2, on device xpu:2 out of 12.
[2024-07-09 21:07:52,139][__main__][INFO] - Hello from rank 17/24, local rank 5, on device xpu:5 out of 12.
[2024-07-09 21:07:52,139][__main__][INFO] - [RANK 8]: Loading local unique mask
[2024-07-09 21:07:52,138][__main__][INFO] - Hello from rank 18/24, local rank 6, on device xpu:6 out of 12.
[2024-07-09 21:07:52,138][__main__][INFO] - Hello from rank 21/24, local rank 9, on device xpu:9 out of 12.
[2024-07-09 21:07:52,139][__main__][INFO] - Hello from rank 13/24, local rank 1, on device xpu:1 out of 12.
[2024-07-09 21:07:52,142][__main__][INFO] - [RANK 10]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,146][__main__][INFO] - [RANK 3]: Loading local unique mask
[2024-07-09 21:07:52,146][__main__][INFO] - [RANK 11]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,147][__main__][INFO] - [RANK 8]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,153][__main__][INFO] - [RANK 3]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,274][__main__][INFO] - [RANK 23]: Loading positions and global node index
[2024-07-09 21:07:52,301][__main__][INFO] - [RANK 23]: Loading edge index
[2024-07-09 21:07:52,328][__main__][INFO] - [RANK 20]: Loading positions and global node index
[2024-07-09 21:07:52,329][__main__][INFO] - [RANK 19]: Loading positions and global node index
[2024-07-09 21:07:52,334][__main__][INFO] - [RANK 15]: Loading positions and global node index
[2024-07-09 21:07:52,334][__main__][INFO] - [RANK 14]: Loading positions and global node index
[2024-07-09 21:07:52,334][__main__][INFO] - [RANK 16]: Loading positions and global node index
[2024-07-09 21:07:52,349][__main__][INFO] - [RANK 22]: Loading positions and global node index
[2024-07-09 21:07:52,351][__main__][INFO] - [RANK 18]: Loading positions and global node index
[2024-07-09 21:07:52,356][__main__][INFO] - [RANK 20]: Loading edge index
[2024-07-09 21:07:52,356][__main__][INFO] - [RANK 19]: Loading edge index
[2024-07-09 21:07:52,360][__main__][INFO] - [RANK 13]: Loading positions and global node index
[2024-07-09 21:07:52,361][__main__][INFO] - [RANK 17]: Loading positions and global node index
[2024-07-09 21:07:52,361][__main__][INFO] - [RANK 14]: Loading edge index
[2024-07-09 21:07:52,361][__main__][INFO] - [RANK 16]: Loading edge index
[2024-07-09 21:07:52,362][__main__][INFO] - [RANK 15]: Loading edge index
[2024-07-09 21:07:52,374][__main__][INFO] - [RANK 21]: Loading positions and global node index
[2024-07-09 21:07:52,379][__main__][INFO] - [RANK 18]: Loading edge index
[2024-07-09 21:07:52,382][__main__][INFO] - [RANK 22]: Loading edge index
[2024-07-09 21:07:52,389][__main__][INFO] - [RANK 13]: Loading edge index
[2024-07-09 21:07:52,389][__main__][INFO] - [RANK 23]: Loading local unique mask
[2024-07-09 21:07:52,390][__main__][INFO] - [RANK 17]: Loading edge index
[2024-07-09 21:07:52,392][__main__][INFO] - [RANK 12]: Loading positions and global node index
[2024-07-09 21:07:52,397][__main__][INFO] - [RANK 23]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,403][__main__][INFO] - [RANK 21]: Loading edge index
[2024-07-09 21:07:52,427][__main__][INFO] - [RANK 12]: Loading edge index

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
RUNNING WITH INPUTS:
profile: false
halo_test: false
verbose: true
seed: 12
epochs: 100
backend: ccl
lr_init: 0.0001
use_noise: true
num_threads: 0
logfreq: 10
ckptfreq: 1000
batch_size: 1
test_batch_size: 1
fp16_allreduce: false
restart: false
hidden_channels: 32
n_mlp_hidden_layers: 5
n_messagePassing_layers: 4
rollout_steps: 1
halo_swap_mode: all_to_all_opt
plot_connectivity: false
work_dir: ${hydra:runtime.cwd}
data_dir: ${work_dir}/datasets/
ckpt_dir: ${work_dir}/ckpt/
model_dir: ${work_dir}/saved_models/
profile_dir: ${work_dir}/outputs/profiles/test/
gnn_outputs_path: /flare/Aurora_deployment/balin/Nek/GNN/weak_scale_data/500k_aurora/24/gnn_outputs_poly_5/

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
[2024-07-09 21:07:52,436][__main__][INFO] - [RANK 0]: Loading positions and global node index
[2024-07-09 21:07:52,448][__main__][INFO] - [RANK 19]: Loading local unique mask
[2024-07-09 21:07:52,451][__main__][INFO] - [RANK 20]: Loading local unique mask
[2024-07-09 21:07:52,453][__main__][INFO] - [RANK 16]: Loading local unique mask
[2024-07-09 21:07:52,456][__main__][INFO] - [RANK 14]: Loading local unique mask
[2024-07-09 21:07:52,456][__main__][INFO] - [RANK 19]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,458][__main__][INFO] - [RANK 15]: Loading local unique mask
[2024-07-09 21:07:52,459][__main__][INFO] - [RANK 20]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,460][__main__][INFO] - [RANK 16]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,464][__main__][INFO] - [RANK 14]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,464][__main__][INFO] - [RANK 0]: Loading edge index
[2024-07-09 21:07:52,466][__main__][INFO] - [RANK 15]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,471][__main__][INFO] - [RANK 18]: Loading local unique mask
[2024-07-09 21:07:52,474][__main__][INFO] - [RANK 22]: Loading local unique mask
[2024-07-09 21:07:52,480][__main__][INFO] - [RANK 18]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,481][__main__][INFO] - [RANK 13]: Loading local unique mask
[2024-07-09 21:07:52,482][__main__][INFO] - [RANK 22]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,485][__main__][INFO] - [RANK 17]: Loading local unique mask
[2024-07-09 21:07:52,490][__main__][INFO] - [RANK 13]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,493][__main__][INFO] - [RANK 17]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,496][__main__][INFO] - [RANK 21]: Loading local unique mask
[2024-07-09 21:07:52,504][__main__][INFO] - [RANK 21]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,517][__main__][INFO] - [RANK 12]: Loading local unique mask
[2024-07-09 21:07:52,526][__main__][INFO] - [RANK 12]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:52,554][__main__][INFO] - [RANK 0]: Loading local unique mask
[2024-07-09 21:07:52,562][__main__][INFO] - [RANK 0]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-09 21:07:55,870][__main__][INFO] - [RANK 4]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:56,124][__main__][INFO] - [RANK 23]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:56,166][__main__][INFO] - [RANK 18]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:56,232][__main__][INFO] - [RANK 14]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:56,244][__main__][INFO] - [RANK 0]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:56,253][__main__][INFO] - [RANK 7]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:56,417][__main__][INFO] - [RANK 1]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:56,514][__main__][INFO] - [RANK 3]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:56,526][__main__][INFO] - [RANK 5]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:56,552][__main__][INFO] - [RANK 2]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:56,689][__main__][INFO] - [RANK 15]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:57,285][__main__][INFO] - [RANK 4]: Getting idx_reduced2full
[2024-07-09 21:07:57,435][__main__][INFO] - [RANK 23]: Getting idx_reduced2full
[2024-07-09 21:07:57,518][__main__][INFO] - [RANK 18]: Getting idx_reduced2full
[2024-07-09 21:07:57,573][__main__][INFO] - [RANK 14]: Getting idx_reduced2full
[2024-07-09 21:07:57,594][__main__][INFO] - [RANK 7]: Getting idx_reduced2full
[2024-07-09 21:07:57,622][__main__][INFO] - [RANK 0]: Getting idx_reduced2full
[2024-07-09 21:07:57,642][__main__][INFO] - [RANK 10]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:57,649][__main__][INFO] - [RANK 9]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:57,685][__main__][INFO] - [RANK 6]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:57,722][__main__][INFO] - [RANK 8]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:57,740][__main__][INFO] - [RANK 11]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:57,785][__main__][INFO] - [RANK 1]: Getting idx_reduced2full
[2024-07-09 21:07:57,904][__main__][INFO] - [RANK 5]: Getting idx_reduced2full
[2024-07-09 21:07:57,912][__main__][INFO] - [RANK 2]: Getting idx_reduced2full
[2024-07-09 21:07:57,920][__main__][INFO] - [RANK 3]: Getting idx_reduced2full
[2024-07-09 21:07:57,921][__main__][INFO] - [RANK 19]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:57,942][__main__][INFO] - [RANK 13]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:57,949][__main__][INFO] - [RANK 22]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:57,962][__main__][INFO] - [RANK 16]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:58,026][__main__][INFO] - [RANK 12]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:58,068][__main__][INFO] - [RANK 15]: Getting idx_reduced2full
[2024-07-09 21:07:58,098][__main__][INFO] - [RANK 21]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:58,118][__main__][INFO] - [RANK 20]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:58,196][__main__][INFO] - [RANK 17]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-09 21:07:59,587][__main__][INFO] - [RANK 6]: Getting idx_reduced2full
[2024-07-09 21:07:59,600][__main__][INFO] - [RANK 11]: Getting idx_reduced2full
[2024-07-09 21:07:59,657][__main__][INFO] - [RANK 10]: Getting idx_reduced2full
[2024-07-09 21:07:59,679][__main__][INFO] - [RANK 9]: Getting idx_reduced2full
[2024-07-09 21:07:59,697][__main__][INFO] - [RANK 8]: Getting idx_reduced2full
[2024-07-09 21:07:59,910][__main__][INFO] - [RANK 12]: Getting idx_reduced2full
[2024-07-09 21:07:59,912][__main__][INFO] - [RANK 19]: Getting idx_reduced2full
[2024-07-09 21:07:59,932][__main__][INFO] - [RANK 13]: Getting idx_reduced2full
[2024-07-09 21:07:59,938][__main__][INFO] - [RANK 22]: Getting idx_reduced2full
[2024-07-09 21:07:59,959][__main__][INFO] - [RANK 20]: Getting idx_reduced2full
[2024-07-09 21:07:59,973][__main__][INFO] - [RANK 16]: Getting idx_reduced2full
[2024-07-09 21:08:00,000][__main__][INFO] - [RANK 21]: Getting idx_reduced2full
[2024-07-09 21:08:00,204][__main__][INFO] - [RANK 17]: Getting idx_reduced2full
[2024-07-09 21:08:02,049][__main__][INFO] - [RANK 4]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:02,055][__main__][INFO] - [RANK 4]: Found 3 neighboring processes: [3 5 8]
[2024-07-09 21:08:02,067][__main__][INFO] - [RANK 23]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:02,072][__main__][INFO] - [RANK 23]: Found 4 neighboring processes: [18 19 21 22]
[2024-07-09 21:08:02,264][__main__][INFO] - [RANK 0]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:02,269][__main__][INFO] - [RANK 0]: Found 3 neighboring processes: [1 2 5]
[2024-07-09 21:08:02,269][__main__][INFO] - In setup_data...
[2024-07-09 21:08:02,282][__main__][INFO] - [RANK 18]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:02,287][__main__][INFO] - [RANK 18]: Found 3 neighboring processes: [19 20 23]
2024:07:09-21:08:02:(143829) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:07:09-21:08:02:(120700) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
[2024-07-09 21:08:02,374][__main__][INFO] - [RANK 7]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:02,379][__main__][INFO] - [RANK 7]: Found 3 neighboring processes: [ 6  8 11]
[2024-07-09 21:08:02,416][__main__][INFO] - [RANK 14]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:02,420][__main__][INFO] - [RANK 14]: Found 4 neighboring processes: [ 9 10 12 13]
2024:07:09-21:08:02:(120695) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
Data(x=[560400, 3], y=[560400, 3], edge_index=[2, 3136160], pos=[560400, 3], global_ids=[528080], local_unique_mask=[528080], halo_unique_mask=[528080], local_ids=[884736], n_nodes_local=528080, n_nodes_halo=32320, halo_info=[32320, 4], edge_weight=[3136160], node_degree=[528080], edge_attr=[3136160, 4])
[2024-07-09 21:08:02,536][__main__][INFO] - Done with setup_data
[2024-07-09 21:08:02,537][__main__][INFO] - Done with build_masks
2024:07:09-21:08:02:(143825) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
[2024-07-09 21:08:02,603][__main__][INFO] - [RANK 1]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:02,608][__main__][INFO] - [RANK 1]: Found 3 neighboring processes: [0 2 5]
2024:07:09-21:08:02:(143832) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
[2024-07-09 21:08:02,624][__main__][INFO] - [RANK 3]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:02,629][__main__][INFO] - [RANK 3]: Found 3 neighboring processes: [4 5 8]
[2024-07-09 21:08:02,680][__main__][INFO] - [RANK 2]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:02,684][__main__][INFO] - [RANK 2]: Found 4 neighboring processes: [ 0  1 21 22]
2024:07:09-21:08:02:(120691) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
[2024-07-09 21:08:02,700][__main__][INFO] - [RANK 5]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:02,704][__main__][INFO] - [RANK 5]: Found 4 neighboring processes: [0 1 3 4]
[2024-07-09 21:08:02,793][__main__][INFO] - [RANK 15]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:02,798][__main__][INFO] - [RANK 15]: Found 3 neighboring processes: [16 17 20]
2024:07:09-21:08:02:(143826) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:07:09-21:08:02:(143828) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:07:09-21:08:02:(143830) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:07:09-21:08:02:(143827) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:07:09-21:08:03:(120692) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
[2024-07-09 21:08:04,350][__main__][INFO] - [RANK 10]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:04,355][__main__][INFO] - [RANK 10]: Found 3 neighboring processes: [ 9 11 14]
[2024-07-09 21:08:04,371][__main__][INFO] - [RANK 11]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:04,375][__main__][INFO] - [RANK 11]: Found 4 neighboring processes: [ 6  7  9 10]
[2024-07-09 21:08:04,429][__main__][INFO] - [RANK 6]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:04,433][__main__][INFO] - [RANK 6]: Found 3 neighboring processes: [ 7  8 11]
[2024-07-09 21:08:04,498][__main__][INFO] - [RANK 8]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:04,502][__main__][INFO] - [RANK 9]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:04,502][__main__][INFO] - [RANK 8]: Found 4 neighboring processes: [3 4 6 7]
[2024-07-09 21:08:04,506][__main__][INFO] - [RANK 9]: Found 3 neighboring processes: [10 11 14]
2024:07:09-21:08:04:(143835) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:07:09-21:08:04:(143836) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:07:09-21:08:04:(143831) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:07:09-21:08:04:(143833) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:07:09-21:08:04:(143834) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
[2024-07-09 21:08:04,760][__main__][INFO] - [RANK 13]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:04,766][__main__][INFO] - [RANK 13]: Found 3 neighboring processes: [12 14 17]
[2024-07-09 21:08:04,777][__main__][INFO] - [RANK 16]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:04,783][__main__][INFO] - [RANK 16]: Found 3 neighboring processes: [15 17 20]
[2024-07-09 21:08:04,792][__main__][INFO] - [RANK 21]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:04,797][__main__][INFO] - [RANK 21]: Found 3 neighboring processes: [ 2 22 23]
[2024-07-09 21:08:04,800][__main__][INFO] - [RANK 20]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:04,804][__main__][INFO] - [RANK 20]: Found 4 neighboring processes: [15 16 18 19]
[2024-07-09 21:08:04,807][__main__][INFO] - [RANK 12]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:04,810][__main__][INFO] - [RANK 19]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:04,812][__main__][INFO] - [RANK 12]: Found 3 neighboring processes: [13 14 17]
[2024-07-09 21:08:04,815][__main__][INFO] - [RANK 19]: Found 3 neighboring processes: [18 20 23]
[2024-07-09 21:08:04,835][__main__][INFO] - [RANK 22]: Assembling halo_ids_list using reduced graph
[2024-07-09 21:08:04,839][__main__][INFO] - [RANK 22]: Found 3 neighboring processes: [ 2 21 23]
2024:07:09-21:08:05:(120690) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:07:09-21:08:05:(120693) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
[2024-07-09 21:08:05,056][__main__][INFO] - [RANK 17]: Assembling halo_ids_list using reduced graph
2024:07:09-21:08:05:(120697) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
[2024-07-09 21:08:05,061][__main__][INFO] - [RANK 17]: Found 4 neighboring processes: [12 13 15 16]
2024:07:09-21:08:05:(120696) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:07:09-21:08:05:(120698) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:07:09-21:08:05:(120689) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:07:09-21:08:05:(120699) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
2024:07:09-21:08:05:(120694) |CCL_WARN| MPI was initialized externally, CCL-MPI specific environment is ignored
[2024-07-09 21:08:06,003][__main__][INFO] - [RANK 18]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,003][__main__][INFO] - [RANK 18]: Send buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3297280, 419840, 0, 0, 419840]
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 1]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,003][__main__][INFO] - [RANK 18]: Receive buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3297280, 419840, 0, 0, 419840]
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 2]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 2]: Send buffers of size [419840, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 419840, 419840, 0]
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 2]: Receive buffers of size [419840, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 419840, 419840, 0]
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 19]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 19]: Send buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3297280, 0, 419840, 0, 0, 419840]
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 0]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 20]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 20]: Send buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 419840, 419840, 0, 419840, 419840, 0, 0, 0, 0]
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 20]: Receive buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 419840, 419840, 0, 419840, 419840, 0, 0, 0, 0]
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 1]: Send buffers of size [3297280, 0, 419840, 0, 0, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 1]: Receive buffers of size [3297280, 0, 419840, 0, 0, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 21]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 21]: Send buffers of size [0, 0, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3297280, 419840]
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 3]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 3]: Send buffers of size [0, 0, 0, 0, 3297280, 419840, 0, 0, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 3]: Receive buffers of size [0, 0, 0, 0, 3297280, 419840, 0, 0, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 22]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 22]: Send buffers of size [0, 0, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3297280, 0, 419840]
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 4]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 4]: Send buffers of size [0, 0, 0, 3297280, 0, 419840, 0, 0, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 4]: Receive buffers of size [0, 0, 0, 3297280, 0, 419840, 0, 0, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 23]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 23]: Send buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 419840, 419840, 0, 419840, 419840, 0]
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 5]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 5]: Send buffers of size [419840, 419840, 0, 419840, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 5]: Receive buffers of size [419840, 419840, 0, 419840, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 12]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 6]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 13]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 13]: Send buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3297280, 0, 419840, 0, 0, 419840, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 7]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 14]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 8]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 15]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 9]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 16]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 10]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 17]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,004][__main__][INFO] - [RANK 11]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 11]: Send buffers of size [0, 0, 0, 0, 0, 0, 419840, 419840, 0, 419840, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 14]: Send buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 419840, 419840, 0, 419840, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 8]: Send buffers of size [0, 0, 0, 419840, 419840, 0, 419840, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 21]: Receive buffers of size [0, 0, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3297280, 419840]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 0]: Send buffers of size [0, 3297280, 419840, 0, 0, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 17]: Send buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 419840, 419840, 0, 419840, 419840, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 9]: Send buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3297280, 419840, 0, 0, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 12]: Send buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3297280, 419840, 0, 0, 419840, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 15]: Send buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3297280, 419840, 0, 0, 419840, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 16]: Send buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3297280, 0, 419840, 0, 0, 419840, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 19]: Receive buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3297280, 0, 419840, 0, 0, 419840]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 22]: Receive buffers of size [0, 0, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3297280, 0, 419840]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 23]: Receive buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 419840, 419840, 0, 419840, 419840, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 12]: Receive buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3297280, 419840, 0, 0, 419840, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 13]: Receive buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3297280, 0, 419840, 0, 0, 419840, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 14]: Receive buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 419840, 419840, 0, 419840, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 15]: Receive buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3297280, 419840, 0, 0, 419840, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 16]: Receive buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3297280, 0, 419840, 0, 0, 419840, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 17]: Receive buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 419840, 419840, 0, 419840, 419840, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 0]: Receive buffers of size [0, 3297280, 419840, 0, 0, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - Done with build_buffers
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 6]: Send buffers of size [0, 0, 0, 0, 0, 0, 0, 3297280, 419840, 0, 0, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 6]: Receive buffers of size [0, 0, 0, 0, 0, 0, 0, 3297280, 419840, 0, 0, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 7]: Send buffers of size [0, 0, 0, 0, 0, 0, 3297280, 0, 419840, 0, 0, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 7]: Receive buffers of size [0, 0, 0, 0, 0, 0, 3297280, 0, 419840, 0, 0, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 8]: Receive buffers of size [0, 0, 0, 419840, 419840, 0, 419840, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 9]: Receive buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3297280, 419840, 0, 0, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 10]: Send buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 3297280, 0, 419840, 0, 0, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 10]: Receive buffers of size [0, 0, 0, 0, 0, 0, 0, 0, 0, 3297280, 0, 419840, 0, 0, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - [RANK 11]: Receive buffers of size [0, 0, 0, 0, 0, 0, 419840, 419840, 0, 419840, 419840, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[2024-07-09 21:08:06,005][__main__][INFO] - In build_model...
[2024-07-09 21:08:06,067][__main__][INFO] - Done with build_model
[2024-07-09 21:08:06,256][__main__][INFO] - [RANK 20] -- model save header : POLY_4_RANK_20_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,256][__main__][INFO] - [RANK 3] -- model save header : POLY_4_RANK_3_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,256][__main__][INFO] - [RANK 12] -- model save header : POLY_4_RANK_12_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,256][__main__][INFO] - [RANK 13] -- model save header : POLY_4_RANK_13_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,256][__main__][INFO] - [RANK 14] -- model save header : POLY_4_RANK_14_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,256][__main__][INFO] - [RANK 15] -- model save header : POLY_4_RANK_15_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,256][__main__][INFO] - [RANK 16] -- model save header : POLY_4_RANK_16_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,256][__main__][INFO] - [RANK 17] -- model save header : POLY_4_RANK_17_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,256][__main__][INFO] - [RANK 18] -- model save header : POLY_4_RANK_18_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,256][__main__][INFO] - [RANK 19] -- model save header : POLY_4_RANK_19_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,256][__main__][INFO] - [RANK 5] -- model save header : POLY_4_RANK_5_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,256][__main__][INFO] - [RANK 21] -- model save header : POLY_4_RANK_21_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,256][__main__][INFO] - [RANK 22] -- model save header : POLY_4_RANK_22_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,256][__main__][INFO] - [RANK 6] -- model save header : POLY_4_RANK_6_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,256][__main__][INFO] - [RANK 23] -- model save header : POLY_4_RANK_23_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,256][__main__][INFO] - [RANK 8] -- model save header : POLY_4_RANK_8_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,256][__main__][INFO] - [RANK 9] -- model save header : POLY_4_RANK_9_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,257][__main__][INFO] - In writeGraphStatistics
[2024-07-09 21:08:06,257][__main__][INFO] - [RANK 1] -- model save header : POLY_4_RANK_1_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,257][__main__][INFO] - [RANK 2] -- model save header : POLY_4_RANK_2_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,257][__main__][INFO] - [RANK 4] -- model save header : POLY_4_RANK_4_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,257][__main__][INFO] - [RANK 7] -- model save header : POLY_4_RANK_7_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,257][__main__][INFO] - [RANK 10] -- model save header : POLY_4_RANK_10_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,257][__main__][INFO] - [RANK 11] -- model save header : POLY_4_RANK_11_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
[2024-07-09 21:08:06,258][__main__][INFO] - [RANK 0] -- model save header : POLY_4_RANK_0_SIZE_24_SEED_12_3_4_32_3_5_4_all_to_all_opt
Directory created by root processor.
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 0] -- number of local nodes: 528080, number of halo nodes: 32320, number of edges: 3136160
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 1] -- number of local nodes: 528080, number of halo nodes: 32320, number of edges: 3136160
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 12] -- number of local nodes: 528080, number of halo nodes: 32320, number of edges: 3136160
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 13] -- number of local nodes: 528080, number of halo nodes: 32320, number of edges: 3136160
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 14] -- number of local nodes: 518400, number of halo nodes: 13120, number of edges: 3097600
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 15] -- number of local nodes: 528080, number of halo nodes: 32320, number of edges: 3136160
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 2] -- number of local nodes: 518400, number of halo nodes: 13120, number of edges: 3097600
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 3] -- number of local nodes: 528080, number of halo nodes: 32320, number of edges: 3136160
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 4] -- number of local nodes: 528080, number of halo nodes: 32320, number of edges: 3136160
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 16] -- number of local nodes: 528080, number of halo nodes: 32320, number of edges: 3136160
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 17] -- number of local nodes: 518400, number of halo nodes: 13120, number of edges: 3097600
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 18] -- number of local nodes: 528080, number of halo nodes: 32320, number of edges: 3136160
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 5] -- number of local nodes: 518400, number of halo nodes: 13120, number of edges: 3097600
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 19] -- number of local nodes: 528080, number of halo nodes: 32320, number of edges: 3136160
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 20] -- number of local nodes: 518400, number of halo nodes: 13120, number of edges: 3097600
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 21] -- number of local nodes: 528080, number of halo nodes: 32320, number of edges: 3136160
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 6] -- number of local nodes: 528080, number of halo nodes: 32320, number of edges: 3136160
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 22] -- number of local nodes: 528080, number of halo nodes: 32320, number of edges: 3136160
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 7] -- number of local nodes: 528080, number of halo nodes: 32320, number of edges: 3136160
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 23] -- number of local nodes: 518400, number of halo nodes: 13120, number of edges: 3097600
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 8] -- number of local nodes: 518400, number of halo nodes: 13120, number of edges: 3097600
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 9] -- number of local nodes: 528080, number of halo nodes: 32320, number of edges: 3136160
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 10] -- number of local nodes: 528080, number of halo nodes: 32320, number of edges: 3136160
[2024-07-09 21:08:06,269][__main__][INFO] - [RANK 11] -- number of local nodes: 518400, number of halo nodes: 13120, number of edges: 3097600
2024:07:09-21:08:07:(143825) |CCL_ERROR| buffer_manager.cpp:101 alloc: condition bytes > 0 failed
unexpected request to allocate zero size buffer
2024:07:09-21:08:07:(120693) |CCL_ERROR| buffer_manager.cpp:101 alloc: condition bytes > 0 failed
unexpected request to allocate zero size buffer
2024:07:09-21:08:07:(120694) |CCL_ERROR| buffer_manager.cpp:101 alloc: condition bytes > 0 failed
unexpected request to allocate zero size buffer
2024:07:09-21:08:07:(143830) |CCL_ERROR| buffer_manager.cpp:101 alloc: condition bytes > 0 failed
unexpected request to allocate zero size buffer
2024:07:09-21:08:07:(120690) |CCL_ERROR| buffer_manager.cpp:101 alloc: condition bytes > 0 failed
unexpected request to allocate zero size buffer
2024:07:09-21:08:07:(143828) |CCL_ERROR| buffer_manager.cpp:101 alloc: condition bytes > 0 failed
unexpected request to allocate zero size buffer
2024:07:09-21:08:07:(143832) |CCL_ERROR| buffer_manager.cpp:101 alloc: condition bytes > 0 failed
unexpected request to allocate zero size buffer
2024:07:09-21:08:07:(120700) |CCL_ERROR| buffer_manager.cpp:101 alloc: condition bytes > 0 failed
unexpected request to allocate zero size buffer
2024:07:09-21:08:07:(120696) |CCL_ERROR| buffer_manager.cpp:101 alloc: condition bytes > 0 failed
unexpected request to allocate zero size buffer
2024:07:09-21:08:07:(143831) |CCL_ERROR| buffer_manager.cpp:101 alloc: condition bytes > 0 failed
unexpected request to allocate zero size buffer
2024:07:09-21:08:07:(143833) |CCL_ERROR| buffer_manager.cpp:101 alloc: condition bytes > 0 failed
unexpected request to allocate zero size buffer
2024:07:09-21:08:07:(120695) |CCL_ERROR| buffer_manager.cpp:101 alloc: condition bytes > 0 failed
unexpected request to allocate zero size buffer
2024:07:09-21:08:07:(120697) |CCL_ERROR| buffer_manager.cpp:101 alloc: condition bytes > 0 failed
unexpected request to allocate zero size buffer
2024:07:09-21:08:07:(143826) |CCL_ERROR| buffer_manager.cpp:101 alloc: condition bytes > 0 failed
unexpected request to allocate zero size buffer
2024:07:09-21:08:07:(143836) |CCL_ERROR| buffer_manager.cpp:101 alloc: condition bytes > 0 failed
unexpected request to allocate zero size buffer
2024:07:09-21:08:07:(120689) |CCL_ERROR| buffer_manager.cpp:101 alloc: condition bytes > 0 failed
unexpected request to allocate zero size buffer
2024:07:09-21:08:07:(143829) |CCL_ERROR| buffer_manager.cpp:101 alloc: condition bytes > 0 failed
unexpected request to allocate zero size buffer
Error executing job with overrides: ['backend=ccl', 'halo_swap_mode=all_to_all_opt', 'gnn_outputs_path=/flare/Aurora_deployment/balin/Nek/GNN/weak_scale_data/500k_aurora/24/gnn_outputs_poly_5/']
Error executing job with overrides: ['backend=ccl', 'halo_swap_mode=all_to_all_opt', 'gnn_outputs_path=/flare/Aurora_deployment/balin/Nek/GNN/weak_scale_data/500k_aurora/24/gnn_outputs_poly_5/']
2024:07:09-21:08:07:(120692) |CCL_ERROR| buffer_manager.cpp:101 alloc: condition bytes > 0 failed
unexpected request to allocate zero size buffer
Error executing job with overrides: ['backend=ccl', 'halo_swap_mode=all_to_all_opt', 'gnn_outputs_path=/flare/Aurora_deployment/balin/Nek/GNN/weak_scale_data/500k_aurora/24/gnn_outputs_poly_5/']
Error executing job with overrides: ['backend=ccl', 'halo_swap_mode=all_to_all_opt', 'gnn_outputs_path=/flare/Aurora_deployment/balin/Nek/GNN/weak_scale_data/500k_aurora/24/gnn_outputs_poly_5/']
Error executing job with overrides: ['backend=ccl', 'halo_swap_mode=all_to_all_opt', 'gnn_outputs_path=/flare/Aurora_deployment/balin/Nek/GNN/weak_scale_data/500k_aurora/24/gnn_outputs_poly_5/']
Error executing job with overrides: ['backend=ccl', 'halo_swap_mode=all_to_all_opt', 'gnn_outputs_path=/flare/Aurora_deployment/balin/Nek/GNN/weak_scale_data/500k_aurora/24/gnn_outputs_poly_5/']
Error executing job with overrides: ['backend=ccl', 'halo_swap_mode=all_to_all_opt', 'gnn_outputs_path=/flare/Aurora_deployment/balin/Nek/GNN/weak_scale_data/500k_aurora/24/gnn_outputs_poly_5/']
Error executing job with overrides: ['backend=ccl', 'halo_swap_mode=all_to_all_opt', 'gnn_outputs_path=/flare/Aurora_deployment/balin/Nek/GNN/weak_scale_data/500k_aurora/24/gnn_outputs_poly_5/']
Error executing job with overrides: ['backend=ccl', 'halo_swap_mode=all_to_all_opt', 'gnn_outputs_path=/flare/Aurora_deployment/balin/Nek/GNN/weak_scale_data/500k_aurora/24/gnn_outputs_poly_5/']
Error executing job with overrides: ['backend=ccl', 'halo_swap_mode=all_to_all_opt', 'gnn_outputs_path=/flare/Aurora_deployment/balin/Nek/GNN/weak_scale_data/500k_aurora/24/gnn_outputs_poly_5/']
Error executing job with overrides: ['backend=ccl', 'halo_swap_mode=all_to_all_opt', 'gnn_outputs_path=/flare/Aurora_deployment/balin/Nek/GNN/weak_scale_data/500k_aurora/24/gnn_outputs_poly_5/']
Error executing job with overrides: ['backend=ccl', 'halo_swap_mode=all_to_all_opt', 'gnn_outputs_path=/flare/Aurora_deployment/balin/Nek/GNN/weak_scale_data/500k_aurora/24/gnn_outputs_poly_5/']
Error executing job with overrides: ['backend=ccl', 'halo_swap_mode=all_to_all_opt', 'gnn_outputs_path=/flare/Aurora_deployment/balin/Nek/GNN/weak_scale_data/500k_aurora/24/gnn_outputs_poly_5/']
Error executing job with overrides: ['backend=ccl', 'halo_swap_mode=all_to_all_opt', 'gnn_outputs_path=/flare/Aurora_deployment/balin/Nek/GNN/weak_scale_data/500k_aurora/24/gnn_outputs_poly_5/']
Error executing job with overrides: ['backend=ccl', 'halo_swap_mode=all_to_all_opt', 'gnn_outputs_path=/flare/Aurora_deployment/balin/Nek/GNN/weak_scale_data/500k_aurora/24/gnn_outputs_poly_5/']
Error executing job with overrides: ['backend=ccl', 'halo_swap_mode=all_to_all_opt', 'gnn_outputs_path=/flare/Aurora_deployment/balin/Nek/GNN/weak_scale_data/500k_aurora/24/gnn_outputs_poly_5/']
Error executing job with overrides: ['backend=ccl', 'halo_swap_mode=all_to_all_opt', 'gnn_outputs_path=/flare/Aurora_deployment/balin/Nek/GNN/weak_scale_data/500k_aurora/24/gnn_outputs_poly_5/']
Error executing job with overrides: ['backend=ccl', 'halo_swap_mode=all_to_all_opt', 'gnn_outputs_path=/flare/Aurora_deployment/balin/Nek/GNN/weak_scale_data/500k_aurora/24/gnn_outputs_poly_5/']
Traceback (most recent call last):
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1431, in main
    train(cfg)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1263, in train
    train_metrics = trainer.train_epoch(epoch)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1154, in train_epoch
    loss = self.train_step(data)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 850, in train_step
    out_gnn = self.model(x = data.x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 102, in forward
    x,_ = self.processor[i](x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 401, in forward
    edge_agg = self.halo_swap(edge_agg,
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 440, in halo_swap
    distnn.all_to_all(buff_recv, buff_send)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 168, in all_to_all
    return _AlltoAll.apply(group, output_tensor_list, *input_tensor_list)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 385, in forward
    dist.all_to_all(
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3659, in all_to_all
    work.wait()
RuntimeError: oneCCL: buffer_manager.cpp:101 alloc: EXCEPTION: unexpected request to allocate zero size buffer

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Traceback (most recent call last):
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1431, in main
    train(cfg)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1263, in train
    train_metrics = trainer.train_epoch(epoch)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1154, in train_epoch
    loss = self.train_step(data)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 850, in train_step
    out_gnn = self.model(x = data.x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 102, in forward
    x,_ = self.processor[i](x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 401, in forward
    edge_agg = self.halo_swap(edge_agg,
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 440, in halo_swap
    distnn.all_to_all(buff_recv, buff_send)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 168, in all_to_all
    return _AlltoAll.apply(group, output_tensor_list, *input_tensor_list)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 385, in forward
    dist.all_to_all(
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3659, in all_to_all
    work.wait()
RuntimeError: oneCCL: buffer_manager.cpp:101 alloc: EXCEPTION: unexpected request to allocate zero size buffer

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Traceback (most recent call last):
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1431, in main
    train(cfg)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1263, in train
    train_metrics = trainer.train_epoch(epoch)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1154, in train_epoch
    loss = self.train_step(data)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 850, in train_step
    out_gnn = self.model(x = data.x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 102, in forward
    x,_ = self.processor[i](x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 401, in forward
    edge_agg = self.halo_swap(edge_agg,
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 440, in halo_swap
    distnn.all_to_all(buff_recv, buff_send)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 168, in all_to_all
    return _AlltoAll.apply(group, output_tensor_list, *input_tensor_list)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 385, in forward
    dist.all_to_all(
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3659, in all_to_all
    work.wait()
RuntimeError: oneCCL: buffer_manager.cpp:101 alloc: EXCEPTION: unexpected request to allocate zero size buffer

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Traceback (most recent call last):
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1431, in main
    train(cfg)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1263, in train
    train_metrics = trainer.train_epoch(epoch)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1154, in train_epoch
    loss = self.train_step(data)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 850, in train_step
    out_gnn = self.model(x = data.x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 102, in forward
    x,_ = self.processor[i](x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 401, in forward
    edge_agg = self.halo_swap(edge_agg,
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 440, in halo_swap
    distnn.all_to_all(buff_recv, buff_send)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 168, in all_to_all
    return _AlltoAll.apply(group, output_tensor_list, *input_tensor_list)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 385, in forward
    dist.all_to_all(
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3659, in all_to_all
    work.wait()
RuntimeError: oneCCL: buffer_manager.cpp:101 alloc: EXCEPTION: unexpected request to allocate zero size buffer

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Traceback (most recent call last):
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1431, in main
    train(cfg)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1263, in train
    train_metrics = trainer.train_epoch(epoch)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1154, in train_epoch
    loss = self.train_step(data)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 850, in train_step
    out_gnn = self.model(x = data.x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 102, in forward
    x,_ = self.processor[i](x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 401, in forward
    edge_agg = self.halo_swap(edge_agg,
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 440, in halo_swap
    distnn.all_to_all(buff_recv, buff_send)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 168, in all_to_all
    return _AlltoAll.apply(group, output_tensor_list, *input_tensor_list)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 385, in forward
    dist.all_to_all(
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3659, in all_to_all
    work.wait()
RuntimeError: oneCCL: buffer_manager.cpp:101 alloc: EXCEPTION: unexpected request to allocate zero size buffer

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Traceback (most recent call last):
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1431, in main
    train(cfg)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1263, in train
    train_metrics = trainer.train_epoch(epoch)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1154, in train_epoch
    loss = self.train_step(data)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 850, in train_step
    out_gnn = self.model(x = data.x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 102, in forward
    x,_ = self.processor[i](x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 401, in forward
    edge_agg = self.halo_swap(edge_agg,
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 440, in halo_swap
    distnn.all_to_all(buff_recv, buff_send)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 168, in all_to_all
    return _AlltoAll.apply(group, output_tensor_list, *input_tensor_list)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 385, in forward
    dist.all_to_all(
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3659, in all_to_all
    work.wait()
RuntimeError: oneCCL: buffer_manager.cpp:101 alloc: EXCEPTION: unexpected request to allocate zero size buffer

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Traceback (most recent call last):
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1431, in main
    train(cfg)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1263, in train
    train_metrics = trainer.train_epoch(epoch)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1154, in train_epoch
    loss = self.train_step(data)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 850, in train_step
    out_gnn = self.model(x = data.x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 102, in forward
    x,_ = self.processor[i](x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 401, in forward
    edge_agg = self.halo_swap(edge_agg,
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 440, in halo_swap
    distnn.all_to_all(buff_recv, buff_send)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 168, in all_to_all
    return _AlltoAll.apply(group, output_tensor_list, *input_tensor_list)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 385, in forward
    dist.all_to_all(
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3659, in all_to_all
    work.wait()
RuntimeError: oneCCL: buffer_manager.cpp:101 alloc: EXCEPTION: unexpected request to allocate zero size buffer

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Traceback (most recent call last):
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1431, in main
    train(cfg)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1263, in train
    train_metrics = trainer.train_epoch(epoch)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1154, in train_epoch
    loss = self.train_step(data)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 850, in train_step
    out_gnn = self.model(x = data.x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 102, in forward
    x,_ = self.processor[i](x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 401, in forward
    edge_agg = self.halo_swap(edge_agg,
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 440, in halo_swap
    distnn.all_to_all(buff_recv, buff_send)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 168, in all_to_all
    return _AlltoAll.apply(group, output_tensor_list, *input_tensor_list)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 385, in forward
    dist.all_to_all(
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3659, in all_to_all
    work.wait()
RuntimeError: oneCCL: buffer_manager.cpp:101 alloc: EXCEPTION: unexpected request to allocate zero size buffer

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Traceback (most recent call last):
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1431, in main
    train(cfg)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1263, in train
    train_metrics = trainer.train_epoch(epoch)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1154, in train_epoch
    loss = self.train_step(data)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 850, in train_step
    out_gnn = self.model(x = data.x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 102, in forward
    x,_ = self.processor[i](x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 401, in forward
    edge_agg = self.halo_swap(edge_agg,
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 440, in halo_swap
    distnn.all_to_all(buff_recv, buff_send)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 168, in all_to_all
    return _AlltoAll.apply(group, output_tensor_list, *input_tensor_list)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 385, in forward
    dist.all_to_all(
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3659, in all_to_all
    work.wait()
RuntimeError: oneCCL: buffer_manager.cpp:101 alloc: EXCEPTION: unexpected request to allocate zero size buffer

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[WARNING] yaksa: 2 leaked handle pool objects
[WARNING] yaksa: 2 leaked handle pool objects
[WARNING] yaksa: 2 leaked handle pool objects
[WARNING] yaksa: 2 leaked handle pool objects
[WARNING] yaksa: 2 leaked handle pool objects
Traceback (most recent call last):
Traceback (most recent call last):
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1431, in main
    train(cfg)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1263, in train
    train_metrics = trainer.train_epoch(epoch)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1154, in train_epoch
    loss = self.train_step(data)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 850, in train_step
    out_gnn = self.model(x = data.x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 102, in forward
    x,_ = self.processor[i](x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/Traceback (most recent call last):
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1431, in main
    train(cfg)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1263, in train
    train_metrics = trainer.train_epoch(epoch)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1154, in train_epoch
    loss = self.train_step(data)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 850, in train_step
    out_gnn = self.model(x = data.x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 102, in forward
    x,_ = self.processor[i](x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1431, in main
    train(cfg)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1263, in train
    train_metrics = trainer.train_epoch(epoch)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1154, in train_epoch
    loss = self.train_step(data)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 850, in train_step
    out_gnn = self.model(x = data.x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 102, in forward
    x,_ = self.processor[i](x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 401, in forward
    edge_agg = self.halo_swap(edge_agg,
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 440, in halo_swap
    distnn.all_to_all(buff_recv, buff_send)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 168, in all_to_all
    return _AlltoAll.apply(group, output_tensor_list, *input_tensor_list)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 385, in forward
    dist.all_to_all(
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3659, in all_to_all
    work.wait()
RuntimeError: oneCCL: buffer_manager.cpp:101 alloc: EXCEPTION: unexpected request to allocate zero size buffer

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 401, in forward
    edge_agg = self.halo_swap(edge_agg,
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 440, in halo_swap
    distnn.all_to_all(buff_recv, buff_send)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 168, in all_to_all
    return _AlltoAll.apply(group, output_tensor_list, *input_tensor_list)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 385, in forward
    dist.all_to_all(
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3659, in all_to_all
    work.wait()
RuntimeError: oneCCL: buffer_manager.cpp:101 alloc: EXCEPTION: unexpected request to allocate zero size buffer

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 401, in forward
    edge_agg = self.halo_swap(edge_agg,
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 440, in halo_swap
    distnn.all_to_all(buff_recv, buff_send)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 168, in all_to_all
    return _AlltoAll.apply(group, output_tensor_list, *input_tensor_list)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 385, in forward
    dist.all_to_all(
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3659, in all_to_all
    work.wait()
RuntimeError: oneCCL: buffer_manager.cpp:101 alloc: EXCEPTION: unexpected request to allocate zero size buffer

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Traceback (most recent call last):
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1431, in main
    train(cfg)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1263, in train
    train_metrics = trainer.train_epoch(epoch)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1154, in train_epoch
    loss = self.train_step(data)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 850, in train_step
    out_gnn = self.model(x = data.x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 102, in forward
    x,_ = self.processor[i](x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 401, in forward
    edge_agg = self.halo_swap(edge_agg,
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 440, in halo_swap
    distnn.all_to_all(buff_recv, buff_send)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 168, in all_to_all
    return _AlltoAll.apply(group, output_tensor_list, *input_tensor_list)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 385, in forward
    dist.all_to_all(
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3659, in all_to_all
    work.wait()
RuntimeError: oneCCL: buffer_manager.cpp:101 alloc: EXCEPTION: unexpected request to allocate zero size buffer

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Traceback (most recent call last):
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1431, in main
    train(cfg)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1263, in train
    train_metrics = trainer.train_epoch(epoch)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1154, in train_epoch
    loss = self.train_step(data)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 850, in train_step
    out_gnn = self.model(x = data.x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 102, in forward
    x,_ = self.processor[i](x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 401, in forward
    edge_agg = self.halo_swap(edge_agg,
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 440, in halo_swap
    distnn.all_to_all(buff_recv, buff_send)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 168, in all_to_all
    return _AlltoAll.apply(group, output_tensor_list, *input_tensor_list)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 385, in forward
    dist.all_to_all(
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3659, in all_to_all
    work.wait()
RuntimeError: oneCCL: buffer_manager.cpp:101 alloc: EXCEPTION: unexpected request to allocate zero size buffer

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[WARNING] yaksa: 2 leaked handle pool objects
[WARNING] yaksa: 2 leaked handle pool objects
Traceback (most recent call last):
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1431, in main
    train(cfg)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1263, in train
    train_metrics = trainer.train_epoch(epoch)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1154, in train_epoch
    loss = self.train_step(data)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 850, in train_step
    out_gnn = self.model(x = data.x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 102, in forward
    x,_ = self.processor[i](x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _Traceback (most recent call last):
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1431, in main
    train(cfg)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1263, in train
    train_metrics = trainer.train_epoch(epoch)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1154, in train_epoch
    loss = self.train_step(data)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 850, in train_step
    out_gnn = self.model(x = data.x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 102, in forward
    x,_ = self.processor[i](x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 401, in forward
    edge_agg = self.halo_swap(edge_agg,
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 440, in halo_swap
    distnn.all_to_all(buff_recv, buff_send)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 168, in all_to_all
    return _AlltoAll.apply(group, output_tensor_list, *input_tensor_list)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 385, in forward
    dist.all_to_all(
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3659, in all_to_all
    work.wait()
RuntimeError: oneCCL: buffer_manager.cpp:101 alloc: EXCEPTION: unexpected request to allocate zero size buffer

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 401, in forward
    edge_agg = self.halo_swap(edge_agg,
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 440, in halo_swap
    distnn.all_to_all(buff_recv, buff_send)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 168, in all_to_all
    return _AlltoAll.apply(group, output_tensor_list, *input_tensor_list)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 385, in forward
    dist.all_to_all(
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3659, in all_to_all
    work.wait()
RuntimeError: oneCCL: buffer_manager.cpp:101 alloc: EXCEPTION: unexpected request to allocate zero size buffer

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Traceback (most recent call last):
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1431, in main
    train(cfg)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1263, in train
    train_metrics = trainer.train_epoch(epoch)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1154, in train_epoch
    loss = self.train_step(data)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 850, in train_step
    out_gnn = self.model(x = data.x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 102, in forward
    x,_ = self.processor[i](x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 401, in forward
    edge_agg = self.halo_swap(edge_agg,
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 440, in halo_swap
    distnn.all_to_all(buff_recv, buff_send)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 168, in all_to_all
    return _AlltoAll.apply(group, output_tensor_list, *input_tensor_list)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 385, in forward
    dist.all_to_all(
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3659, in all_to_all
    work.wait()
RuntimeError: oneCCL: buffer_manager.cpp:101 alloc: EXCEPTION: unexpected request to allocate zero size buffer

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Traceback (most recent call last):
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1431, in main
    train(cfg)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1263, in train
    train_metrics = trainer.train_epoch(epoch)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 1154, in train_epoch
    loss = self.train_step(data)
  File "/flare/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/main.py", line 850, in train_step
    out_gnn = self.model(x = data.x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1519, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1355, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 102, in forward
    x,_ = self.processor[i](x,
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 401, in forward
    edge_agg = self.halo_swap(edge_agg,
  File "/lus/flare/projects/Aurora_deployment/balin/Nek/GNN/GNN/NekRS-ML/gnn.py", line 440, in halo_swap
    distnn.all_to_all(buff_recv, buff_send)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 168, in all_to_all
    return _AlltoAll.apply(group, output_tensor_list, *input_tensor_list)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/nn/functional.py", line 385, in forward
    dist.all_to_all(
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
    return func(*args, **kwargs)
  File "/opt/aurora/24.086.0/frameworks/aurora_nre_models_frameworks-2024.1/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 3659, in all_to_all
    work.wait()
RuntimeError: oneCCL: buffer_manager.cpp:101 alloc: EXCEPTION: unexpected request to allocate zero size buffer

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[WARNING] yaksa: 2 leaked handle pool objects
[WARNING] yaksa: 2 leaked handle pool objects
x4010c7s6b0n0.hostmgmt2010.cm.aurora.alcf.anl.gov: rank 0 exited with code 1
x4010c7s6b0n0.hostmgmt2010.cm.aurora.alcf.anl.gov: rank 8 died from signal 15
Tue 09 Jul 2024 09:08:09 PM UTC
