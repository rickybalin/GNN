Lmod Warning: Some features of the current Cray PE are built on top of newer
CUDA versions and may cause incompatibility issue.
You may still use this version of CUDA toolkit after carefully validating your
application. 
While processing the following module(s):
    Module fullname                Module Filename
    ---------------                ---------------
    cudatoolkit-standalone/11.8.0  /soft/modulefiles/cudatoolkit-standalone/11.8.0.lua

Lmod Warning: Some features of the current Cray PE are built on top of newer
CUDA versions and may cause incompatibility issue.
You may still use this version of CUDA toolkit after carefully validating your
application. 
While processing the following module(s):
    Module fullname                Module Filename
    ---------------                ---------------
    cudatoolkit-standalone/11.8.0  /soft/modulefiles/cudatoolkit-standalone/11.8.0.lua

Loaded modules:

Currently Loaded Modules:
  1) libfabric/1.15.2.0       9) cray-pmi/6.1.13
  2) craype-network-ofi      10) cray-pals/1.3.4
  3) perftools-base/23.12.0  11) cray-libpals/1.3.4
  4) darshan/3.4.4           12) craype-x86-milan
  5) gcc-native/12.3         13) PrgEnv-gnu/8.5.0
  6) craype/2.7.30           14) cudatoolkit-standalone/11.8.0
  7) cray-dsmml/0.2.2        15) cray-hdf5-parallel/1.12.2.9
  8) cray-mpich/8.1.28       16) conda/2024-04-29

 


Torch version: 2.3.0
Torch CUDA version: 12.4
NCCL version: (2, 20, 5)
cuDNN version: 90100
Torch Geometric version: 2.5.3

Number of nodes: 2
Number of ML ranks per node: 4
Number of ML total ranks: 8

Running script /eagle/projects/datascience/balin/Nek/GNN/GNN/NekRS-ML/main.py
with arguments backend=nccl halo_swap_mode=all_to_all_opt gnn_outputs_path=/lus/eagle/projects/datascience/sbarwey/codes/nek/nekrs_cases/examples_v23_gnn/tgv_weak_scaling/ne_128_v2/gnn_outputs_poly_5/

Tue 02 Jul 2024 01:59:02 PM UTC
[2024-07-02 13:59:08,724][__main__][INFO] - Hello from rank 0/8, local rank 0, on device cuda:0 out of 4.
[2024-07-02 13:59:09,248][__main__][INFO] - Hello from rank 1/8, local rank 1, on device cuda:1 out of 4.
[2024-07-02 13:59:09,250][__main__][INFO] - Hello from rank 2/8, local rank 2, on device cuda:2 out of 4.
[2024-07-02 13:59:09,250][__main__][INFO] - Hello from rank 3/8, local rank 3, on device cuda:3 out of 4.
[2024-07-02 13:59:09,606][__main__][INFO] - Hello from rank 4/8, local rank 0, on device cuda:0 out of 4.
[2024-07-02 13:59:09,770][__main__][INFO] - [RANK 1]: Loading positions and global node index
[2024-07-02 13:59:09,778][__main__][INFO] - [RANK 2]: Loading positions and global node index
[2024-07-02 13:59:09,800][__main__][INFO] - [RANK 1]: Loading edge index
[2024-07-02 13:59:09,808][__main__][INFO] - [RANK 2]: Loading edge index
[2024-07-02 13:59:09,856][__main__][INFO] - [RANK 1]: Loading local unique mask
[2024-07-02 13:59:09,860][__main__][INFO] - [RANK 1]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-02 13:59:09,865][__main__][INFO] - [RANK 2]: Loading local unique mask
[2024-07-02 13:59:09,869][__main__][INFO] - [RANK 2]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-02 13:59:10,038][__main__][INFO] - [RANK 3]: Loading positions and global node index
[2024-07-02 13:59:10,060][__main__][INFO] - [RANK 3]: Loading edge index
[2024-07-02 13:59:10,114][__main__][INFO] - Hello from rank 5/8, local rank 1, on device cuda:1 out of 4.
[2024-07-02 13:59:10,115][__main__][INFO] - Hello from rank 6/8, local rank 2, on device cuda:2 out of 4.
[2024-07-02 13:59:10,115][__main__][INFO] - Hello from rank 7/8, local rank 3, on device cuda:3 out of 4.
[2024-07-02 13:59:10,119][__main__][INFO] - [RANK 3]: Loading local unique mask
[2024-07-02 13:59:10,123][__main__][INFO] - [RANK 3]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-02 13:59:10,438][__main__][INFO] - [RANK 4]: Loading positions and global node index
[2024-07-02 13:59:10,476][__main__][INFO] - [RANK 4]: Loading edge index
[2024-07-02 13:59:10,537][__main__][INFO] - [RANK 4]: Loading local unique mask
[2024-07-02 13:59:10,540][__main__][INFO] - [RANK 4]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-02 13:59:10,746][__main__][INFO] - [RANK 5]: Loading positions and global node index
[2024-07-02 13:59:10,767][__main__][INFO] - [RANK 5]: Loading edge index
[2024-07-02 13:59:10,824][__main__][INFO] - [RANK 5]: Loading local unique mask
[2024-07-02 13:59:10,828][__main__][INFO] - [RANK 5]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-02 13:59:10,890][__main__][INFO] - [RANK 6]: Loading positions and global node index
[2024-07-02 13:59:10,902][__main__][INFO] - [RANK 7]: Loading positions and global node index
[2024-07-02 13:59:10,910][__main__][INFO] - [RANK 6]: Loading edge index

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
RUNNING WITH INPUTS:
profile: false
halo_test: false
verbose: true
seed: 12
epochs: 50
backend: nccl
lr_init: 0.0001
use_noise: true
num_threads: 0
logfreq: 1
ckptfreq: 1000
batch_size: 1
test_batch_size: 1
fp16_allreduce: false
restart: false
hidden_channels: 8
n_mlp_hidden_layers: 2
n_messagePassing_layers: 4
rollout_steps: 1
halo_swap_mode: all_to_all_opt
plot_connectivity: false
work_dir: ${hydra:runtime.cwd}
data_dir: ${work_dir}/datasets/
ckpt_dir: ${work_dir}/ckpt/
model_dir: ${work_dir}/saved_models/
profile_dir: ${work_dir}/outputs/profiles/test/
gnn_outputs_path: /lus/eagle/projects/datascience/sbarwey/codes/nek/nekrs_cases/examples_v23_gnn/tgv_weak_scaling/ne_128_v2/gnn_outputs_poly_5/

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
[2024-07-02 13:59:10,910][__main__][INFO] - [RANK 0]: Loading positions and global node index
[2024-07-02 13:59:10,924][__main__][INFO] - [RANK 7]: Loading edge index
[2024-07-02 13:59:10,932][__main__][INFO] - [RANK 0]: Loading edge index
[2024-07-02 13:59:10,968][__main__][INFO] - [RANK 6]: Loading local unique mask
[2024-07-02 13:59:10,971][__main__][INFO] - [RANK 6]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-02 13:59:10,982][__main__][INFO] - [RANK 7]: Loading local unique mask
[2024-07-02 13:59:10,986][__main__][INFO] - [RANK 7]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-02 13:59:10,990][__main__][INFO] - [RANK 0]: Loading local unique mask
[2024-07-02 13:59:10,994][__main__][INFO] - [RANK 0]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-02 13:59:11,539][__main__][INFO] - [RANK 2]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-02 13:59:11,542][__main__][INFO] - [RANK 1]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-02 13:59:11,829][__main__][INFO] - [RANK 3]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-02 13:59:12,208][__main__][INFO] - [RANK 4]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-02 13:59:12,246][__main__][INFO] - [RANK 2]: Getting idx_reduced2full
[2024-07-02 13:59:12,246][__main__][INFO] - [RANK 1]: Getting idx_reduced2full
[2024-07-02 13:59:12,485][__main__][INFO] - [RANK 3]: Getting idx_reduced2full
[2024-07-02 13:59:12,494][__main__][INFO] - [RANK 5]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-02 13:59:12,638][__main__][INFO] - [RANK 6]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-02 13:59:12,658][__main__][INFO] - [RANK 0]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-02 13:59:12,658][__main__][INFO] - [RANK 7]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-02 13:59:12,928][__main__][INFO] - [RANK 4]: Getting idx_reduced2full
[2024-07-02 13:59:13,149][__main__][INFO] - [RANK 5]: Getting idx_reduced2full
[2024-07-02 13:59:13,294][__main__][INFO] - [RANK 6]: Getting idx_reduced2full
[2024-07-02 13:59:13,313][__main__][INFO] - [RANK 7]: Getting idx_reduced2full
[2024-07-02 13:59:13,314][__main__][INFO] - [RANK 0]: Getting idx_reduced2full
[2024-07-02 13:59:18,235][__main__][INFO] - [RANK 1]: Assembling halo_ids_list using reduced graph
[2024-07-02 13:59:18,288][__main__][INFO] - [RANK 1]: Found 2 neighboring processes: [0 6]
[2024-07-02 13:59:18,363][__main__][INFO] - [RANK 2]: Assembling halo_ids_list using reduced graph
[2024-07-02 13:59:18,365][__main__][INFO] - [RANK 2]: Found 2 neighboring processes: [3 5]
[2024-07-02 13:59:18,688][__main__][INFO] - [RANK 3]: Assembling halo_ids_list using reduced graph
[2024-07-02 13:59:18,690][__main__][INFO] - [RANK 3]: Found 2 neighboring processes: [0 2]
[2024-07-02 13:59:18,905][__main__][INFO] - [RANK 4]: Assembling halo_ids_list using reduced graph
[2024-07-02 13:59:18,964][__main__][INFO] - [RANK 4]: Found 2 neighboring processes: [5 7]
[2024-07-02 13:59:19,184][__main__][INFO] - [RANK 5]: Assembling halo_ids_list using reduced graph
[2024-07-02 13:59:19,185][__main__][INFO] - [RANK 5]: Found 2 neighboring processes: [2 4]
[2024-07-02 13:59:19,287][__main__][INFO] - [RANK 6]: Assembling halo_ids_list using reduced graph
[2024-07-02 13:59:19,290][__main__][INFO] - [RANK 6]: Found 2 neighboring processes: [1 7]
[2024-07-02 13:59:19,344][__main__][INFO] - [RANK 0]: Assembling halo_ids_list using reduced graph
[2024-07-02 13:59:19,344][__main__][INFO] - [RANK 7]: Assembling halo_ids_list using reduced graph
[2024-07-02 13:59:19,346][__main__][INFO] - [RANK 7]: Found 2 neighboring processes: [4 6]
[2024-07-02 13:59:19,347][__main__][INFO] - [RANK 0]: Found 2 neighboring processes: [1 3]
[2024-07-02 13:59:19,347][__main__][INFO] - In setup_data...
Data(x=[531200, 3], y=[531200, 3], edge_index=[2, 3097600], pos=[531200, 3], global_ids=[518400], local_unique_mask=[518400], halo_unique_mask=[518400], local_ids=[884736], n_nodes_local=518400, n_nodes_halo=12800, halo_info=[12800, 4], edge_weight=[3097600], node_degree=[518400], edge_attr=[3097600, 4])
[2024-07-02 13:59:19,518][__main__][INFO] - Done with setup_data
[2024-07-02 13:59:19,519][__main__][INFO] - Done with build_masks
[2024-07-02 13:59:20,495][__main__][INFO] - [RANK 1]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-02 13:59:20,495][__main__][INFO] - [RANK 2]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-02 13:59:20,495][__main__][INFO] - [RANK 3]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-02 13:59:20,495][__main__][INFO] - [RANK 0]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-02 13:59:20,495][__main__][INFO] - [RANK 0]: Send buffers of size [0, 204800, 0, 204800, 0, 0, 0, 0]
[2024-07-02 13:59:20,495][__main__][INFO] - [RANK 0]: Receive buffers of size [0, 204800, 0, 204800, 0, 0, 0, 0]
[2024-07-02 13:59:20,495][__main__][INFO] - Done with build_buffers
[2024-07-02 13:59:20,495][__main__][INFO] - In build_model...
[2024-07-02 13:59:20,495][__main__][INFO] - [RANK 4]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-02 13:59:20,495][__main__][INFO] - [RANK 5]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-02 13:59:20,495][__main__][INFO] - [RANK 5]: Send buffers of size [0, 0, 204800, 0, 204800, 0, 0, 0]
[2024-07-02 13:59:20,495][__main__][INFO] - [RANK 5]: Receive buffers of size [0, 0, 204800, 0, 204800, 0, 0, 0]
[2024-07-02 13:59:20,495][__main__][INFO] - [RANK 6]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-02 13:59:20,495][__main__][INFO] - [RANK 6]: Send buffers of size [0, 204800, 0, 0, 0, 0, 0, 204800]
[2024-07-02 13:59:20,495][__main__][INFO] - [RANK 6]: Receive buffers of size [0, 204800, 0, 0, 0, 0, 0, 204800]
[2024-07-02 13:59:20,495][__main__][INFO] - [RANK 4]: Send buffers of size [0, 0, 0, 0, 0, 204800, 0, 204800]
[2024-07-02 13:59:20,495][__main__][INFO] - [RANK 4]: Receive buffers of size [0, 0, 0, 0, 0, 204800, 0, 204800]
[2024-07-02 13:59:20,495][__main__][INFO] - [RANK 7]: Created send and receive buffers for all_to_all_opt halo exchange:
[2024-07-02 13:59:20,495][__main__][INFO] - [RANK 7]: Send buffers of size [0, 0, 0, 0, 204800, 0, 204800, 0]
[2024-07-02 13:59:20,495][__main__][INFO] - [RANK 7]: Receive buffers of size [0, 0, 0, 0, 204800, 0, 204800, 0]
[2024-07-02 13:59:20,527][__main__][INFO] - Done with build_model
[2024-07-02 13:59:20,556][__main__][INFO] - [RANK 2]: Send buffers of size [0, 0, 0, 204800, 0, 204800, 0, 0]
[2024-07-02 13:59:20,556][__main__][INFO] - [RANK 1]: Send buffers of size [204800, 0, 0, 0, 0, 0, 204800, 0]
[2024-07-02 13:59:20,556][__main__][INFO] - [RANK 1]: Receive buffers of size [204800, 0, 0, 0, 0, 0, 204800, 0]
[2024-07-02 13:59:20,556][__main__][INFO] - [RANK 2]: Receive buffers of size [0, 0, 0, 204800, 0, 204800, 0, 0]
[2024-07-02 13:59:20,556][__main__][INFO] - [RANK 3]: Send buffers of size [204800, 0, 204800, 0, 0, 0, 0, 0]
[2024-07-02 13:59:20,556][__main__][INFO] - [RANK 3]: Receive buffers of size [204800, 0, 204800, 0, 0, 0, 0, 0]
/lus/eagle/projects/datascience/balin/Nek/GNN/env/gnn/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
[2024-07-02 13:59:20,599][__main__][INFO] - [RANK 5] -- model save header : POLY_5_RANK_5_SIZE_8_SEED_12_3_4_8_3_2_4_all_to_all_opt
/lus/eagle/projects/datascience/balin/Nek/GNN/env/gnn/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
[2024-07-02 13:59:20,598][__main__][INFO] - [RANK 6] -- model save header : POLY_5_RANK_6_SIZE_8_SEED_12_3_4_8_3_2_4_all_to_all_opt
/lus/eagle/projects/datascience/balin/Nek/GNN/env/gnn/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
[2024-07-02 13:59:20,598][__main__][INFO] - [RANK 7] -- model save header : POLY_5_RANK_7_SIZE_8_SEED_12_3_4_8_3_2_4_all_to_all_opt
/lus/eagle/projects/datascience/balin/Nek/GNN/env/gnn/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
[2024-07-02 13:59:20,599][__main__][INFO] - In writeGraphStatistics
[2024-07-02 13:59:20,599][__main__][INFO] - [RANK 0] -- model save header : POLY_5_RANK_0_SIZE_8_SEED_12_3_4_8_3_2_4_all_to_all_opt
[2024-07-02 13:59:20,599][__main__][INFO] - [RANK 4] -- model save header : POLY_5_RANK_4_SIZE_8_SEED_12_3_4_8_3_2_4_all_to_all_opt
/lus/eagle/projects/datascience/balin/Nek/GNN/env/gnn/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
/lus/eagle/projects/datascience/balin/Nek/GNN/env/gnn/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
[2024-07-02 13:59:20,599][__main__][INFO] - [RANK 2] -- model save header : POLY_5_RANK_2_SIZE_8_SEED_12_3_4_8_3_2_4_all_to_all_opt
[2024-07-02 13:59:20,599][__main__][INFO] - [RANK 3] -- model save header : POLY_5_RANK_3_SIZE_8_SEED_12_3_4_8_3_2_4_all_to_all_opt
/lus/eagle/projects/datascience/balin/Nek/GNN/env/gnn/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
[2024-07-02 13:59:20,600][__main__][INFO] - [RANK 1] -- model save header : POLY_5_RANK_1_SIZE_8_SEED_12_3_4_8_3_2_4_all_to_all_opt
/lus/eagle/projects/datascience/balin/Nek/GNN/env/gnn/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Directory created by root processor.
[2024-07-02 13:59:20,604][__main__][INFO] - [RANK 0] -- number of local nodes: 518400, number of halo nodes: 12800, number of edges: 3097600
[2024-07-02 13:59:20,604][__main__][INFO] - [RANK 4] -- number of local nodes: 518400, number of halo nodes: 12800, number of edges: 3097600
[2024-07-02 13:59:20,604][__main__][INFO] - [RANK 1] -- number of local nodes: 518400, number of halo nodes: 12800, number of edges: 3097600
[2024-07-02 13:59:20,604][__main__][INFO] - [RANK 5] -- number of local nodes: 518400, number of halo nodes: 12800, number of edges: 3097600
[2024-07-02 13:59:20,604][__main__][INFO] - [RANK 6] -- number of local nodes: 518400, number of halo nodes: 12800, number of edges: 3097600
[2024-07-02 13:59:20,604][__main__][INFO] - [RANK 2] -- number of local nodes: 518400, number of halo nodes: 12800, number of edges: 3097600
[2024-07-02 13:59:20,604][__main__][INFO] - [RANK 3] -- number of local nodes: 518400, number of halo nodes: 12800, number of edges: 3097600
[2024-07-02 13:59:20,604][__main__][INFO] - [RANK 7] -- number of local nodes: 518400, number of halo nodes: 12800, number of edges: 3097600
[2024-07-02 13:59:21,825][__main__][INFO] - [0] [1/50: Batch 1 (100%)] epoch=1.0000 time[s]=1.1994 batch_loss=0.1112 running_loss=0.1112
[2024-07-02 13:59:21,882][__main__][INFO] - ----------------------
[2024-07-02 13:59:21,883][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:21,883][__main__][INFO] - ----------------------
[2024-07-02 13:59:21,883][__main__][INFO] - ---------------------------------------------
[2024-07-02 13:59:21,883][__main__][INFO] - [TRAIN]  loss=1.1118e-01  epoch_time=1.22 sec
[2024-07-02 13:59:21,883][__main__][INFO] - ---------------------------------------------
[2024-07-02 13:59:22,234][__main__][INFO] - [0] [2/50: Batch 1 (100%)] epoch=2.0000 time[s]=0.3317 batch_loss=0.1103 running_loss=0.1103
[2024-07-02 13:59:22,267][__main__][INFO] - ----------------------
[2024-07-02 13:59:22,267][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:22,267][__main__][INFO] - ----------------------
[2024-07-02 13:59:22,267][__main__][INFO] - ----------------------------------------------
[2024-07-02 13:59:22,267][__main__][INFO] - [TRAIN]  loss=1.1029e-01  epoch_time=0.351 sec
[2024-07-02 13:59:22,267][__main__][INFO] - ----------------------------------------------
[2024-07-02 13:59:22,634][__main__][INFO] - [0] [3/50: Batch 1 (100%)] epoch=3.0000 time[s]=0.3465 batch_loss=0.1094 running_loss=0.1094
[2024-07-02 13:59:22,653][__main__][INFO] - ----------------------
[2024-07-02 13:59:22,654][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:22,654][__main__][INFO] - ----------------------
[2024-07-02 13:59:22,654][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:22,654][__main__][INFO] - [TRAIN]  loss=1.0941e-01  epoch_time=0.3669 sec
[2024-07-02 13:59:22,654][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:22,998][__main__][INFO] - [0] [4/50: Batch 1 (100%)] epoch=4.0000 time[s]=0.3240 batch_loss=0.1085 running_loss=0.1085
[2024-07-02 13:59:23,017][__main__][INFO] - ----------------------
[2024-07-02 13:59:23,018][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:23,018][__main__][INFO] - ----------------------
[2024-07-02 13:59:23,018][__main__][INFO] - ----------------------------------------------
[2024-07-02 13:59:23,018][__main__][INFO] - [TRAIN]  loss=1.0853e-01  epoch_time=0.344 sec
[2024-07-02 13:59:23,018][__main__][INFO] - ----------------------------------------------
[2024-07-02 13:59:23,365][__main__][INFO] - [0] [5/50: Batch 1 (100%)] epoch=5.0000 time[s]=0.3280 batch_loss=0.1077 running_loss=0.1077
[2024-07-02 13:59:23,396][__main__][INFO] - ----------------------
[2024-07-02 13:59:23,410][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:23,410][__main__][INFO] - ----------------------
[2024-07-02 13:59:23,410][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:23,410][__main__][INFO] - [TRAIN]  loss=1.0766e-01  epoch_time=0.3478 sec
[2024-07-02 13:59:23,410][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:23,750][__main__][INFO] - [0] [6/50: Batch 1 (100%)] epoch=6.0000 time[s]=0.3199 batch_loss=0.1068 running_loss=0.1068
[2024-07-02 13:59:23,770][__main__][INFO] - ----------------------
[2024-07-02 13:59:23,770][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:23,770][__main__][INFO] - ----------------------
[2024-07-02 13:59:23,770][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:23,770][__main__][INFO] - [TRAIN]  loss=1.0680e-01  epoch_time=0.3394 sec
[2024-07-02 13:59:23,770][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:24,114][__main__][INFO] - [0] [7/50: Batch 1 (100%)] epoch=7.0000 time[s]=0.3241 batch_loss=0.1060 running_loss=0.1060
[2024-07-02 13:59:24,134][__main__][INFO] - ----------------------
[2024-07-02 13:59:24,134][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:24,134][__main__][INFO] - ----------------------
[2024-07-02 13:59:24,134][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:24,134][__main__][INFO] - [TRAIN]  loss=1.0597e-01  epoch_time=0.3437 sec
[2024-07-02 13:59:24,134][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:24,478][__main__][INFO] - [0] [8/50: Batch 1 (100%)] epoch=8.0000 time[s]=0.3243 batch_loss=0.1052 running_loss=0.1052
[2024-07-02 13:59:24,509][__main__][INFO] - ----------------------
[2024-07-02 13:59:24,509][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:24,509][__main__][INFO] - ----------------------
[2024-07-02 13:59:24,509][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:24,509][__main__][INFO] - [TRAIN]  loss=1.0516e-01  epoch_time=0.3438 sec
[2024-07-02 13:59:24,509][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:24,854][__main__][INFO] - [0] [9/50: Batch 1 (100%)] epoch=9.0000 time[s]=0.3241 batch_loss=0.1044 running_loss=0.1044
[2024-07-02 13:59:24,880][__main__][INFO] - ----------------------
[2024-07-02 13:59:24,880][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:24,880][__main__][INFO] - ----------------------
[2024-07-02 13:59:24,880][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:24,880][__main__][INFO] - [TRAIN]  loss=1.0437e-01  epoch_time=0.3448 sec
[2024-07-02 13:59:24,880][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:25,266][__main__][INFO] - [0] [10/50: Batch 1 (100%)] epoch=10.0000 time[s]=0.3662 batch_loss=0.1036 running_loss=0.1036
[2024-07-02 13:59:25,297][__main__][INFO] - ----------------------
[2024-07-02 13:59:25,297][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:25,297][__main__][INFO] - ----------------------
[2024-07-02 13:59:25,297][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:25,297][__main__][INFO] - [TRAIN]  loss=1.0360e-01  epoch_time=0.3859 sec
[2024-07-02 13:59:25,297][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:25,662][__main__][INFO] - [0] [11/50: Batch 1 (100%)] epoch=11.0000 time[s]=0.3442 batch_loss=0.1029 running_loss=0.1029
[2024-07-02 13:59:25,693][__main__][INFO] - ----------------------
[2024-07-02 13:59:25,693][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:25,693][__main__][INFO] - ----------------------
[2024-07-02 13:59:25,693][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:25,693][__main__][INFO] - [TRAIN]  loss=1.0286e-01  epoch_time=0.3643 sec
[2024-07-02 13:59:25,693][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:26,038][__main__][INFO] - [0] [12/50: Batch 1 (100%)] epoch=12.0000 time[s]=0.3241 batch_loss=0.1021 running_loss=0.1021
[2024-07-02 13:59:26,058][__main__][INFO] - ----------------------
[2024-07-02 13:59:26,058][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:26,058][__main__][INFO] - ----------------------
[2024-07-02 13:59:26,058][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:26,058][__main__][INFO] - [TRAIN]  loss=1.0214e-01  epoch_time=0.3444 sec
[2024-07-02 13:59:26,058][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:26,402][__main__][INFO] - [0] [13/50: Batch 1 (100%)] epoch=13.0000 time[s]=0.3244 batch_loss=0.1014 running_loss=0.1014
[2024-07-02 13:59:26,427][__main__][INFO] - ----------------------
[2024-07-02 13:59:26,427][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:26,427][__main__][INFO] - ----------------------
[2024-07-02 13:59:26,427][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:26,427][__main__][INFO] - [TRAIN]  loss=1.0144e-01  epoch_time=0.3438 sec
[2024-07-02 13:59:26,427][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:26,778][__main__][INFO] - [0] [14/50: Batch 1 (100%)] epoch=14.0000 time[s]=0.3306 batch_loss=0.1008 running_loss=0.1008
[2024-07-02 13:59:26,799][__main__][INFO] - ----------------------
[2024-07-02 13:59:26,799][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:26,799][__main__][INFO] - ----------------------
[2024-07-02 13:59:26,799][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:26,799][__main__][INFO] - [TRAIN]  loss=1.0076e-01  epoch_time=0.3504 sec
[2024-07-02 13:59:26,799][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:27,158][__main__][INFO] - [0] [15/50: Batch 1 (100%)] epoch=15.0000 time[s]=0.3384 batch_loss=0.1001 running_loss=0.1001
[2024-07-02 13:59:27,189][__main__][INFO] - ----------------------
[2024-07-02 13:59:27,189][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:27,189][__main__][INFO] - ----------------------
[2024-07-02 13:59:27,189][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:27,189][__main__][INFO] - [TRAIN]  loss=1.0011e-01  epoch_time=0.3584 sec
[2024-07-02 13:59:27,189][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:27,542][__main__][INFO] - [0] [16/50: Batch 1 (100%)] epoch=16.0000 time[s]=0.3331 batch_loss=0.0995 running_loss=0.0995
[2024-07-02 13:59:27,573][__main__][INFO] - ----------------------
[2024-07-02 13:59:27,573][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:27,573][__main__][INFO] - ----------------------
[2024-07-02 13:59:27,573][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:27,573][__main__][INFO] - [TRAIN]  loss=9.9478e-02  epoch_time=0.3526 sec
[2024-07-02 13:59:27,573][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:27,958][__main__][INFO] - [0] [17/50: Batch 1 (100%)] epoch=17.0000 time[s]=0.3646 batch_loss=0.0989 running_loss=0.0989
[2024-07-02 13:59:27,977][__main__][INFO] - ----------------------
[2024-07-02 13:59:27,978][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:27,978][__main__][INFO] - ----------------------
[2024-07-02 13:59:27,978][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:27,978][__main__][INFO] - [TRAIN]  loss=9.8873e-02  epoch_time=0.3843 sec
[2024-07-02 13:59:27,978][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:28,322][__main__][INFO] - [0] [18/50: Batch 1 (100%)] epoch=18.0000 time[s]=0.3243 batch_loss=0.0983 running_loss=0.0983
[2024-07-02 13:59:28,342][__main__][INFO] - ----------------------
[2024-07-02 13:59:28,342][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:28,342][__main__][INFO] - ----------------------
[2024-07-02 13:59:28,342][__main__][INFO] - ----------------------------------------------
[2024-07-02 13:59:28,342][__main__][INFO] - [TRAIN]  loss=9.8290e-02  epoch_time=0.344 sec
[2024-07-02 13:59:28,342][__main__][INFO] - ----------------------------------------------
[2024-07-02 13:59:28,689][__main__][INFO] - [0] [19/50: Batch 1 (100%)] epoch=19.0000 time[s]=0.3280 batch_loss=0.0977 running_loss=0.0977
[2024-07-02 13:59:28,717][__main__][INFO] - ----------------------
[2024-07-02 13:59:28,718][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:28,718][__main__][INFO] - ----------------------
[2024-07-02 13:59:28,718][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:28,718][__main__][INFO] - [TRAIN]  loss=9.7730e-02  epoch_time=0.3476 sec
[2024-07-02 13:59:28,718][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:29,057][__main__][INFO] - [0] [20/50: Batch 1 (100%)] epoch=20.0000 time[s]=0.3200 batch_loss=0.0972 running_loss=0.0972
[2024-07-02 13:59:29,082][__main__][INFO] - ----------------------
[2024-07-02 13:59:29,083][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:29,083][__main__][INFO] - ----------------------
[2024-07-02 13:59:29,083][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:29,083][__main__][INFO] - [TRAIN]  loss=9.7192e-02  epoch_time=0.3398 sec
[2024-07-02 13:59:29,083][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:29,450][__main__][INFO] - [0] [21/50: Batch 1 (100%)] epoch=21.0000 time[s]=0.3474 batch_loss=0.0967 running_loss=0.0967
[2024-07-02 13:59:29,480][__main__][INFO] - ----------------------
[2024-07-02 13:59:29,480][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:29,480][__main__][INFO] - ----------------------
[2024-07-02 13:59:29,480][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:29,480][__main__][INFO] - [TRAIN]  loss=9.6674e-02  epoch_time=0.3669 sec
[2024-07-02 13:59:29,480][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:29,822][__main__][INFO] - [0] [22/50: Batch 1 (100%)] epoch=22.0000 time[s]=0.3215 batch_loss=0.0962 running_loss=0.0962
[2024-07-02 13:59:29,845][__main__][INFO] - ----------------------
[2024-07-02 13:59:29,845][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:29,845][__main__][INFO] - ----------------------
[2024-07-02 13:59:29,845][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:29,845][__main__][INFO] - [TRAIN]  loss=9.6177e-02  epoch_time=0.3413 sec
[2024-07-02 13:59:29,845][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:30,190][__main__][INFO] - [0] [23/50: Batch 1 (100%)] epoch=23.0000 time[s]=0.3248 batch_loss=0.0957 running_loss=0.0957
[2024-07-02 13:59:30,212][__main__][INFO] - ----------------------
[2024-07-02 13:59:30,212][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:30,212][__main__][INFO] - ----------------------
[2024-07-02 13:59:30,212][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:30,212][__main__][INFO] - [TRAIN]  loss=9.5697e-02  epoch_time=0.3443 sec
[2024-07-02 13:59:30,212][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:30,562][__main__][INFO] - [0] [24/50: Batch 1 (100%)] epoch=24.0000 time[s]=0.3300 batch_loss=0.0952 running_loss=0.0952
[2024-07-02 13:59:30,582][__main__][INFO] - ----------------------
[2024-07-02 13:59:30,582][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:30,582][__main__][INFO] - ----------------------
[2024-07-02 13:59:30,582][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:30,582][__main__][INFO] - [TRAIN]  loss=9.5235e-02  epoch_time=0.3497 sec
[2024-07-02 13:59:30,582][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:30,946][__main__][INFO] - [0] [25/50: Batch 1 (100%)] epoch=25.0000 time[s]=0.3437 batch_loss=0.0948 running_loss=0.0948
[2024-07-02 13:59:30,966][__main__][INFO] - ----------------------
[2024-07-02 13:59:30,966][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:30,966][__main__][INFO] - ----------------------
[2024-07-02 13:59:30,966][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:30,966][__main__][INFO] - [TRAIN]  loss=9.4790e-02  epoch_time=0.3634 sec
[2024-07-02 13:59:30,966][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:31,310][__main__][INFO] - [0] [26/50: Batch 1 (100%)] epoch=26.0000 time[s]=0.3240 batch_loss=0.0944 running_loss=0.0944
[2024-07-02 13:59:31,329][__main__][INFO] - ----------------------
[2024-07-02 13:59:31,329][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:31,330][__main__][INFO] - ----------------------
[2024-07-02 13:59:31,330][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:31,330][__main__][INFO] - [TRAIN]  loss=9.4359e-02  epoch_time=0.3437 sec
[2024-07-02 13:59:31,330][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:31,681][__main__][INFO] - [0] [27/50: Batch 1 (100%)] epoch=27.0000 time[s]=0.3322 batch_loss=0.0939 running_loss=0.0939
[2024-07-02 13:59:31,713][__main__][INFO] - ----------------------
[2024-07-02 13:59:31,713][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:31,713][__main__][INFO] - ----------------------
[2024-07-02 13:59:31,713][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:31,713][__main__][INFO] - [TRAIN]  loss=9.3944e-02  epoch_time=0.3519 sec
[2024-07-02 13:59:31,713][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:32,062][__main__][INFO] - [0] [28/50: Batch 1 (100%)] epoch=28.0000 time[s]=0.3290 batch_loss=0.0935 running_loss=0.0935
[2024-07-02 13:59:32,088][__main__][INFO] - ----------------------
[2024-07-02 13:59:32,088][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:32,088][__main__][INFO] - ----------------------
[2024-07-02 13:59:32,088][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:32,088][__main__][INFO] - [TRAIN]  loss=9.3543e-02  epoch_time=0.3485 sec
[2024-07-02 13:59:32,088][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:32,458][__main__][INFO] - [0] [29/50: Batch 1 (100%)] epoch=29.0000 time[s]=0.3441 batch_loss=0.0932 running_loss=0.0932
[2024-07-02 13:59:32,478][__main__][INFO] - ----------------------
[2024-07-02 13:59:32,479][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:32,479][__main__][INFO] - ----------------------
[2024-07-02 13:59:32,479][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:32,479][__main__][INFO] - [TRAIN]  loss=9.3155e-02  epoch_time=0.3697 sec
[2024-07-02 13:59:32,479][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:32,822][__main__][INFO] - [0] [30/50: Batch 1 (100%)] epoch=30.0000 time[s]=0.3230 batch_loss=0.0928 running_loss=0.0928
[2024-07-02 13:59:32,842][__main__][INFO] - ----------------------
[2024-07-02 13:59:32,842][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:32,842][__main__][INFO] - ----------------------
[2024-07-02 13:59:32,842][__main__][INFO] - ----------------------------------------------
[2024-07-02 13:59:32,842][__main__][INFO] - [TRAIN]  loss=9.2778e-02  epoch_time=0.343 sec
[2024-07-02 13:59:32,842][__main__][INFO] - ----------------------------------------------
[2024-07-02 13:59:33,186][__main__][INFO] - [0] [31/50: Batch 1 (100%)] epoch=31.0000 time[s]=0.3238 batch_loss=0.0924 running_loss=0.0924
[2024-07-02 13:59:33,214][__main__][INFO] - ----------------------
[2024-07-02 13:59:33,214][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:33,214][__main__][INFO] - ----------------------
[2024-07-02 13:59:33,214][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:33,214][__main__][INFO] - [TRAIN]  loss=9.2413e-02  epoch_time=0.3434 sec
[2024-07-02 13:59:33,214][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:33,590][__main__][INFO] - [0] [32/50: Batch 1 (100%)] epoch=32.0000 time[s]=0.3555 batch_loss=0.0921 running_loss=0.0921
[2024-07-02 13:59:33,615][__main__][INFO] - ----------------------
[2024-07-02 13:59:33,616][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:33,616][__main__][INFO] - ----------------------
[2024-07-02 13:59:33,616][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:33,616][__main__][INFO] - [TRAIN]  loss=9.2057e-02  epoch_time=0.3754 sec
[2024-07-02 13:59:33,616][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:33,990][__main__][INFO] - [0] [33/50: Batch 1 (100%)] epoch=33.0000 time[s]=0.3542 batch_loss=0.0917 running_loss=0.0917
[2024-07-02 13:59:34,010][__main__][INFO] - ----------------------
[2024-07-02 13:59:34,010][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:34,010][__main__][INFO] - ----------------------
[2024-07-02 13:59:34,010][__main__][INFO] - ----------------------------------------------
[2024-07-02 13:59:34,010][__main__][INFO] - [TRAIN]  loss=9.1709e-02  epoch_time=0.374 sec
[2024-07-02 13:59:34,010][__main__][INFO] - ----------------------------------------------
[2024-07-02 13:59:34,353][__main__][INFO] - [0] [34/50: Batch 1 (100%)] epoch=34.0000 time[s]=0.3236 batch_loss=0.0914 running_loss=0.0914
[2024-07-02 13:59:34,385][__main__][INFO] - ----------------------
[2024-07-02 13:59:34,386][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:34,386][__main__][INFO] - ----------------------
[2024-07-02 13:59:34,386][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:34,386][__main__][INFO] - [TRAIN]  loss=9.1369e-02  epoch_time=0.3435 sec
[2024-07-02 13:59:34,386][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:34,750][__main__][INFO] - [0] [35/50: Batch 1 (100%)] epoch=35.0000 time[s]=0.3443 batch_loss=0.0910 running_loss=0.0910
[2024-07-02 13:59:34,775][__main__][INFO] - ----------------------
[2024-07-02 13:59:34,775][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:34,775][__main__][INFO] - ----------------------
[2024-07-02 13:59:34,775][__main__][INFO] - ----------------------------------------------
[2024-07-02 13:59:34,775][__main__][INFO] - [TRAIN]  loss=9.1037e-02  epoch_time=0.364 sec
[2024-07-02 13:59:34,775][__main__][INFO] - ----------------------------------------------
[2024-07-02 13:59:35,118][__main__][INFO] - [0] [36/50: Batch 1 (100%)] epoch=36.0000 time[s]=0.3231 batch_loss=0.0907 running_loss=0.0907
[2024-07-02 13:59:35,137][__main__][INFO] - ----------------------
[2024-07-02 13:59:35,138][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:35,138][__main__][INFO] - ----------------------
[2024-07-02 13:59:35,138][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:35,138][__main__][INFO] - [TRAIN]  loss=9.0710e-02  epoch_time=0.3429 sec
[2024-07-02 13:59:35,138][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:35,486][__main__][INFO] - [0] [37/50: Batch 1 (100%)] epoch=37.0000 time[s]=0.3278 batch_loss=0.0904 running_loss=0.0904
[2024-07-02 13:59:35,510][__main__][INFO] - ----------------------
[2024-07-02 13:59:35,510][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:35,510][__main__][INFO] - ----------------------
[2024-07-02 13:59:35,510][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:35,510][__main__][INFO] - [TRAIN]  loss=9.0390e-02  epoch_time=0.3486 sec
[2024-07-02 13:59:35,510][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:35,889][__main__][INFO] - [0] [38/50: Batch 1 (100%)] epoch=38.0000 time[s]=0.3583 batch_loss=0.0901 running_loss=0.0901
[2024-07-02 13:59:35,921][__main__][INFO] - ----------------------
[2024-07-02 13:59:35,921][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:35,921][__main__][INFO] - ----------------------
[2024-07-02 13:59:35,921][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:35,921][__main__][INFO] - [TRAIN]  loss=9.0075e-02  epoch_time=0.3794 sec
[2024-07-02 13:59:35,921][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:36,273][__main__][INFO] - [0] [39/50: Batch 1 (100%)] epoch=39.0000 time[s]=0.3319 batch_loss=0.0898 running_loss=0.0898
[2024-07-02 13:59:36,298][__main__][INFO] - ----------------------
[2024-07-02 13:59:36,298][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:36,298][__main__][INFO] - ----------------------
[2024-07-02 13:59:36,298][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:36,298][__main__][INFO] - [TRAIN]  loss=8.9766e-02  epoch_time=0.3521 sec
[2024-07-02 13:59:36,298][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:36,686][__main__][INFO] - [0] [40/50: Batch 1 (100%)] epoch=40.0000 time[s]=0.3666 batch_loss=0.0895 running_loss=0.0895
[2024-07-02 13:59:36,717][__main__][INFO] - ----------------------
[2024-07-02 13:59:36,717][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:36,717][__main__][INFO] - ----------------------
[2024-07-02 13:59:36,717][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:36,717][__main__][INFO] - [TRAIN]  loss=8.9462e-02  epoch_time=0.3874 sec
[2024-07-02 13:59:36,717][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:37,057][__main__][INFO] - [0] [41/50: Batch 1 (100%)] epoch=41.0000 time[s]=0.3207 batch_loss=0.0892 running_loss=0.0892
[2024-07-02 13:59:37,101][__main__][INFO] - ----------------------
[2024-07-02 13:59:37,101][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:37,101][__main__][INFO] - ----------------------
[2024-07-02 13:59:37,101][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:37,101][__main__][INFO] - [TRAIN]  loss=8.9163e-02  epoch_time=0.3404 sec
[2024-07-02 13:59:37,101][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:37,454][__main__][INFO] - [0] [42/50: Batch 1 (100%)] epoch=42.0000 time[s]=0.3328 batch_loss=0.0889 running_loss=0.0889
[2024-07-02 13:59:37,478][__main__][INFO] - ----------------------
[2024-07-02 13:59:37,478][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:37,478][__main__][INFO] - ----------------------
[2024-07-02 13:59:37,479][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:37,479][__main__][INFO] - [TRAIN]  loss=8.8869e-02  epoch_time=0.3523 sec
[2024-07-02 13:59:37,479][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:37,834][__main__][INFO] - [0] [43/50: Batch 1 (100%)] epoch=43.0000 time[s]=0.3351 batch_loss=0.0886 running_loss=0.0886
[2024-07-02 13:59:37,854][__main__][INFO] - ----------------------
[2024-07-02 13:59:37,854][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:37,854][__main__][INFO] - ----------------------
[2024-07-02 13:59:37,854][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:37,854][__main__][INFO] - [TRAIN]  loss=8.8580e-02  epoch_time=0.3552 sec
[2024-07-02 13:59:37,854][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:38,198][__main__][INFO] - [0] [44/50: Batch 1 (100%)] epoch=44.0000 time[s]=0.3225 batch_loss=0.0883 running_loss=0.0883
[2024-07-02 13:59:38,224][__main__][INFO] - ----------------------
[2024-07-02 13:59:38,225][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:38,225][__main__][INFO] - ----------------------
[2024-07-02 13:59:38,225][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:38,225][__main__][INFO] - [TRAIN]  loss=8.8297e-02  epoch_time=0.3437 sec
[2024-07-02 13:59:38,225][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:38,590][__main__][INFO] - [0] [45/50: Batch 1 (100%)] epoch=45.0000 time[s]=0.3450 batch_loss=0.0880 running_loss=0.0880
[2024-07-02 13:59:38,621][__main__][INFO] - ----------------------
[2024-07-02 13:59:38,621][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:38,621][__main__][INFO] - ----------------------
[2024-07-02 13:59:38,621][__main__][INFO] - ----------------------------------------------
[2024-07-02 13:59:38,621][__main__][INFO] - [TRAIN]  loss=8.8018e-02  epoch_time=0.365 sec
[2024-07-02 13:59:38,621][__main__][INFO] - ----------------------------------------------
[2024-07-02 13:59:38,994][__main__][INFO] - [0] [46/50: Batch 1 (100%)] epoch=46.0000 time[s]=0.3522 batch_loss=0.0877 running_loss=0.0877
[2024-07-02 13:59:39,014][__main__][INFO] - ----------------------
[2024-07-02 13:59:39,014][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:39,014][__main__][INFO] - ----------------------
[2024-07-02 13:59:39,014][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:39,014][__main__][INFO] - [TRAIN]  loss=8.7745e-02  epoch_time=0.3723 sec
[2024-07-02 13:59:39,014][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:39,358][__main__][INFO] - [0] [47/50: Batch 1 (100%)] epoch=47.0000 time[s]=0.3240 batch_loss=0.0875 running_loss=0.0875
[2024-07-02 13:59:39,389][__main__][INFO] - ----------------------
[2024-07-02 13:59:39,389][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:39,389][__main__][INFO] - ----------------------
[2024-07-02 13:59:39,389][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:39,389][__main__][INFO] - [TRAIN]  loss=8.7477e-02  epoch_time=0.3438 sec
[2024-07-02 13:59:39,389][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:39,758][__main__][INFO] - [0] [48/50: Batch 1 (100%)] epoch=48.0000 time[s]=0.3486 batch_loss=0.0872 running_loss=0.0872
[2024-07-02 13:59:39,785][__main__][INFO] - ----------------------
[2024-07-02 13:59:39,785][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:39,785][__main__][INFO] - ----------------------
[2024-07-02 13:59:39,785][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:39,785][__main__][INFO] - [TRAIN]  loss=8.7215e-02  epoch_time=0.3683 sec
[2024-07-02 13:59:39,785][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:40,154][__main__][INFO] - [0] [49/50: Batch 1 (100%)] epoch=49.0000 time[s]=0.3489 batch_loss=0.0870 running_loss=0.0870
[2024-07-02 13:59:40,174][__main__][INFO] - ----------------------
[2024-07-02 13:59:40,174][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:40,174][__main__][INFO] - ----------------------
[2024-07-02 13:59:40,174][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:40,174][__main__][INFO] - [TRAIN]  loss=8.6959e-02  epoch_time=0.3684 sec
[2024-07-02 13:59:40,174][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:40,517][__main__][INFO] - [0] [50/50: Batch 1 (100%)] epoch=50.0000 time[s]=0.3228 batch_loss=0.0867 running_loss=0.0867
[2024-07-02 13:59:40,538][__main__][INFO] - [2] :: Total training time: 31.28709125518799 seconds
[2024-07-02 13:59:40,538][__main__][INFO] - [4] :: Total training time: 30.878077030181885 seconds
[2024-07-02 13:59:40,538][__main__][INFO] - [3] :: Total training time: 31.28697657585144 seconds
[2024-07-02 13:59:40,538][__main__][INFO] - [7] :: Total training time: 30.42226505279541 seconds
[2024-07-02 13:59:40,538][__main__][INFO] - [6] :: Total training time: 30.422640323638916 seconds
[2024-07-02 13:59:40,538][__main__][INFO] - ----------------------
[2024-07-02 13:59:40,538][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:59:40,538][__main__][INFO] - [5] :: Total training time: 30.422791481018066 seconds
[2024-07-02 13:59:40,538][__main__][INFO] - ----------------------
[2024-07-02 13:59:40,538][__main__][INFO] - [1] :: Total training time: 31.28855562210083 seconds
[2024-07-02 13:59:40,538][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:40,538][__main__][INFO] - [TRAIN]  loss=8.6709e-02  epoch_time=0.3431 sec
[2024-07-02 13:59:40,538][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:59:40,538][__main__][INFO] - [0] :: Total training time: 31.812502145767212 seconds

Summary of performance data:
Total training time: 31.812502145767212
Training epoch [s] : min = 3.394046e-01 , max = 3.926179e-01 , avg = 3.550163e-01 , std = 1.281111e-02 
Training throughput [nodes/s] : min = 1.320368e+06 , max = 1.527381e+06 , avg = 1.462056e+06 , std = 5.107414e+04 
Average parallel training throughout [nodes/s] : 1.169645e+07
Training batch [s] : min = 3.196571e-01 , max = 3.696270e-01 , avg = 3.354283e-01 , std = 1.265843e-02 
forwardPass [s] : min = 7.300949e-02 , max = 1.032250e-01 , avg = 7.963728e-02 , std = 8.523558e-03 
backwardPass [s] : min = 1.567700e-01 , max = 1.844454e-01 , avg = 1.643414e-01 , std = 6.145848e-03 
loss [s] : min = 4.012585e-04 , max = 5.438089e-03 , avg = 1.386313e-03 , std = 1.750236e-03 
optimizerStep [s] : min = 1.077414e-03 , max = 2.183437e-03 , avg = 1.126930e-03 , std = 1.380626e-04 
dataTransfer [s] : min = 9.952784e-03 , max = 1.086164e-02 , avg = 1.024114e-02 , std = 1.856587e-04 
bufferInit [s] : min = 1.826286e-04 , max = 2.429485e-04 , avg = 2.027543e-04 , std = 8.966230e-06 
Tue 02 Jul 2024 01:59:43 PM UTC
