Lmod Warning: Some features of the current Cray PE are built on top of newer
CUDA versions and may cause incompatibility issue.
You may still use this version of CUDA toolkit after carefully validating your
application. 
While processing the following module(s):
    Module fullname                Module Filename
    ---------------                ---------------
    cudatoolkit-standalone/11.8.0  /soft/modulefiles/cudatoolkit-standalone/11.8.0.lua

Lmod Warning: Some features of the current Cray PE are built on top of newer
CUDA versions and may cause incompatibility issue.
You may still use this version of CUDA toolkit after carefully validating your
application. 
While processing the following module(s):
    Module fullname                Module Filename
    ---------------                ---------------
    cudatoolkit-standalone/11.8.0  /soft/modulefiles/cudatoolkit-standalone/11.8.0.lua

Loaded modules:

Currently Loaded Modules:
  1) libfabric/1.15.2.0       9) cray-pmi/6.1.13
  2) craype-network-ofi      10) cray-pals/1.3.4
  3) perftools-base/23.12.0  11) cray-libpals/1.3.4
  4) darshan/3.4.4           12) craype-x86-milan
  5) gcc-native/12.3         13) PrgEnv-gnu/8.5.0
  6) craype/2.7.30           14) cudatoolkit-standalone/11.8.0
  7) cray-dsmml/0.2.2        15) cray-hdf5-parallel/1.12.2.9
  8) cray-mpich/8.1.28       16) conda/2024-04-29

 


Torch version: 2.3.0
Torch CUDA version: 12.4
NCCL version: (2, 20, 5)
cuDNN version: 90100
Torch Geometric version: 2.5.3

Number of nodes: 2
Number of ML ranks per node: 4
Number of ML total ranks: 8

Running script /eagle/projects/datascience/balin/Nek/GNN/GNN/NekRS-ML/main.py
with arguments backend=nccl halo_swap_mode=all_to_all gnn_outputs_path=/lus/eagle/projects/datascience/sbarwey/codes/nek/nekrs_cases/examples_v23_gnn/tgv_weak_scaling/ne_128_v2/gnn_outputs_poly_5/

Tue 02 Jul 2024 01:57:27 PM UTC
[2024-07-02 13:57:33,977][__main__][INFO] - Hello from rank 0/8, local rank 0, on device cuda:0 out of 4.
[2024-07-02 13:57:34,528][__main__][INFO] - Hello from rank 1/8, local rank 1, on device cuda:1 out of 4.
[2024-07-02 13:57:34,529][__main__][INFO] - Hello from rank 2/8, local rank 2, on device cuda:2 out of 4.
[2024-07-02 13:57:34,530][__main__][INFO] - Hello from rank 3/8, local rank 3, on device cuda:3 out of 4.
[2024-07-02 13:57:35,134][__main__][INFO] - Hello from rank 4/8, local rank 0, on device cuda:0 out of 4.
[2024-07-02 13:57:35,322][__main__][INFO] - [RANK 2]: Loading positions and global node index
[2024-07-02 13:57:35,322][__main__][INFO] - [RANK 3]: Loading positions and global node index
[2024-07-02 13:57:35,334][__main__][INFO] - [RANK 1]: Loading positions and global node index
[2024-07-02 13:57:35,343][__main__][INFO] - [RANK 2]: Loading edge index
[2024-07-02 13:57:35,343][__main__][INFO] - [RANK 3]: Loading edge index
[2024-07-02 13:57:35,354][__main__][INFO] - [RANK 1]: Loading edge index
[2024-07-02 13:57:35,398][__main__][INFO] - [RANK 2]: Loading local unique mask
[2024-07-02 13:57:35,400][__main__][INFO] - [RANK 3]: Loading local unique mask
[2024-07-02 13:57:35,403][__main__][INFO] - [RANK 2]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-02 13:57:35,403][__main__][INFO] - [RANK 3]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-02 13:57:35,408][__main__][INFO] - [RANK 1]: Loading local unique mask
[2024-07-02 13:57:35,412][__main__][INFO] - [RANK 1]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-02 13:57:35,653][__main__][INFO] - Hello from rank 6/8, local rank 2, on device cuda:2 out of 4.
[2024-07-02 13:57:35,655][__main__][INFO] - Hello from rank 5/8, local rank 1, on device cuda:1 out of 4.
[2024-07-02 13:57:35,655][__main__][INFO] - Hello from rank 7/8, local rank 3, on device cuda:3 out of 4.
[2024-07-02 13:57:35,894][__main__][INFO] - [RANK 4]: Loading positions and global node index
[2024-07-02 13:57:35,914][__main__][INFO] - [RANK 4]: Loading edge index
[2024-07-02 13:57:35,968][__main__][INFO] - [RANK 4]: Loading local unique mask
[2024-07-02 13:57:35,973][__main__][INFO] - [RANK 4]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-02 13:57:36,418][__main__][INFO] - [RANK 5]: Loading positions and global node index
[2024-07-02 13:57:36,426][__main__][INFO] - [RANK 7]: Loading positions and global node index
[2024-07-02 13:57:36,441][__main__][INFO] - [RANK 5]: Loading edge index
[2024-07-02 13:57:36,442][__main__][INFO] - [RANK 6]: Loading positions and global node index
[2024-07-02 13:57:36,445][__main__][INFO] - [RANK 7]: Loading edge index

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
RUNNING WITH INPUTS:
profile: false
halo_test: false
verbose: true
seed: 12
epochs: 50
backend: nccl
lr_init: 0.0001
use_noise: true
num_threads: 0
logfreq: 1
ckptfreq: 1000
batch_size: 1
test_batch_size: 1
fp16_allreduce: false
restart: false
hidden_channels: 8
n_mlp_hidden_layers: 2
n_messagePassing_layers: 4
rollout_steps: 1
halo_swap_mode: all_to_all
plot_connectivity: false
work_dir: ${hydra:runtime.cwd}
data_dir: ${work_dir}/datasets/
ckpt_dir: ${work_dir}/ckpt/
model_dir: ${work_dir}/saved_models/
profile_dir: ${work_dir}/outputs/profiles/test/
gnn_outputs_path: /lus/eagle/projects/datascience/sbarwey/codes/nek/nekrs_cases/examples_v23_gnn/tgv_weak_scaling/ne_128_v2/gnn_outputs_poly_5/

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
[2024-07-02 13:57:36,446][__main__][INFO] - [RANK 0]: Loading positions and global node index
[2024-07-02 13:57:36,462][__main__][INFO] - [RANK 6]: Loading edge index
[2024-07-02 13:57:36,466][__main__][INFO] - [RANK 0]: Loading edge index
[2024-07-02 13:57:36,497][__main__][INFO] - [RANK 5]: Loading local unique mask
[2024-07-02 13:57:36,500][__main__][INFO] - [RANK 7]: Loading local unique mask
[2024-07-02 13:57:36,500][__main__][INFO] - [RANK 5]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-02 13:57:36,504][__main__][INFO] - [RANK 7]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-02 13:57:36,518][__main__][INFO] - [RANK 6]: Loading local unique mask
[2024-07-02 13:57:36,520][__main__][INFO] - [RANK 0]: Loading local unique mask
[2024-07-02 13:57:36,523][__main__][INFO] - [RANK 6]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-02 13:57:36,525][__main__][INFO] - [RANK 0]: Making the FULL GLL-based graph with overlapping nodes
[2024-07-02 13:57:37,071][__main__][INFO] - [RANK 1]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-02 13:57:37,072][__main__][INFO] - [RANK 2]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-02 13:57:37,088][__main__][INFO] - [RANK 3]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-02 13:57:37,637][__main__][INFO] - [RANK 4]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-02 13:57:37,726][__main__][INFO] - [RANK 2]: Getting idx_reduced2full
[2024-07-02 13:57:37,728][__main__][INFO] - [RANK 1]: Getting idx_reduced2full
[2024-07-02 13:57:37,743][__main__][INFO] - [RANK 3]: Getting idx_reduced2full
[2024-07-02 13:57:38,164][__main__][INFO] - [RANK 7]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-02 13:57:38,168][__main__][INFO] - [RANK 5]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-02 13:57:38,188][__main__][INFO] - [RANK 6]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-02 13:57:38,192][__main__][INFO] - [RANK 0]: Making the REDUCED GLL-based graph with non-overlapping nodes
[2024-07-02 13:57:38,283][__main__][INFO] - [RANK 4]: Getting idx_reduced2full
[2024-07-02 13:57:38,821][__main__][INFO] - [RANK 7]: Getting idx_reduced2full
[2024-07-02 13:57:38,825][__main__][INFO] - [RANK 5]: Getting idx_reduced2full
[2024-07-02 13:57:38,842][__main__][INFO] - [RANK 6]: Getting idx_reduced2full
[2024-07-02 13:57:38,850][__main__][INFO] - [RANK 0]: Getting idx_reduced2full
[2024-07-02 13:57:43,717][__main__][INFO] - [RANK 3]: Assembling halo_ids_list using reduced graph
[2024-07-02 13:57:43,720][__main__][INFO] - [RANK 3]: Found 2 neighboring processes: [0 2]
[2024-07-02 13:57:43,758][__main__][INFO] - [RANK 1]: Assembling halo_ids_list using reduced graph
[2024-07-02 13:57:43,760][__main__][INFO] - [RANK 1]: Found 2 neighboring processes: [0 6]
[2024-07-02 13:57:43,806][__main__][INFO] - [RANK 2]: Assembling halo_ids_list using reduced graph
[2024-07-02 13:57:43,809][__main__][INFO] - [RANK 2]: Found 2 neighboring processes: [3 5]
[2024-07-02 13:57:44,217][__main__][INFO] - [RANK 4]: Assembling halo_ids_list using reduced graph
[2024-07-02 13:57:44,219][__main__][INFO] - [RANK 4]: Found 2 neighboring processes: [5 7]
[2024-07-02 13:57:44,744][__main__][INFO] - [RANK 6]: Assembling halo_ids_list using reduced graph
[2024-07-02 13:57:44,747][__main__][INFO] - [RANK 6]: Found 2 neighboring processes: [1 7]
[2024-07-02 13:57:44,822][__main__][INFO] - [RANK 0]: Assembling halo_ids_list using reduced graph
[2024-07-02 13:57:44,824][__main__][INFO] - [RANK 0]: Found 2 neighboring processes: [1 3]
[2024-07-02 13:57:44,825][__main__][INFO] - In setup_data...
[2024-07-02 13:57:44,833][__main__][INFO] - [RANK 7]: Assembling halo_ids_list using reduced graph
[2024-07-02 13:57:44,835][__main__][INFO] - [RANK 7]: Found 2 neighboring processes: [4 6]
[2024-07-02 13:57:44,888][__main__][INFO] - [RANK 5]: Assembling halo_ids_list using reduced graph
[2024-07-02 13:57:44,890][__main__][INFO] - [RANK 5]: Found 2 neighboring processes: [2 4]
Data(x=[531200, 3], y=[531200, 3], edge_index=[2, 3097600], pos=[531200, 3], global_ids=[518400], local_unique_mask=[518400], halo_unique_mask=[518400], local_ids=[884736], n_nodes_local=518400, n_nodes_halo=12800, halo_info=[12800, 4], edge_weight=[3097600], node_degree=[518400], edge_attr=[3097600, 4])
[2024-07-02 13:57:44,997][__main__][INFO] - Done with setup_data
[2024-07-02 13:57:44,997][__main__][INFO] - Done with build_masks
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 0]: Created send and receive buffers for all_to_all halo exchange:
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 4]: Created send and receive buffers for all_to_all halo exchange:
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 5]: Created send and receive buffers for all_to_all halo exchange:
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 5]: Send buffers of size [204800, 204800, 204800, 204800, 204800, 204800, 204800, 204800]
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 5]: Receive buffers of size [204800, 204800, 204800, 204800, 204800, 204800, 204800, 204800]
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 1]: Created send and receive buffers for all_to_all halo exchange:
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 1]: Send buffers of size [204800, 204800, 204800, 204800, 204800, 204800, 204800, 204800]
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 1]: Receive buffers of size [204800, 204800, 204800, 204800, 204800, 204800, 204800, 204800]
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 2]: Created send and receive buffers for all_to_all halo exchange:
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 2]: Send buffers of size [204800, 204800, 204800, 204800, 204800, 204800, 204800, 204800]
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 2]: Receive buffers of size [204800, 204800, 204800, 204800, 204800, 204800, 204800, 204800]
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 0]: Send buffers of size [204800, 204800, 204800, 204800, 204800, 204800, 204800, 204800]
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 0]: Receive buffers of size [204800, 204800, 204800, 204800, 204800, 204800, 204800, 204800]
[2024-07-02 13:57:45,968][__main__][INFO] - Done with build_buffers
[2024-07-02 13:57:45,968][__main__][INFO] - In build_model...
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 3]: Created send and receive buffers for all_to_all halo exchange:
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 3]: Send buffers of size [204800, 204800, 204800, 204800, 204800, 204800, 204800, 204800]
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 3]: Receive buffers of size [204800, 204800, 204800, 204800, 204800, 204800, 204800, 204800]
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 6]: Created send and receive buffers for all_to_all halo exchange:
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 6]: Send buffers of size [204800, 204800, 204800, 204800, 204800, 204800, 204800, 204800]
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 6]: Receive buffers of size [204800, 204800, 204800, 204800, 204800, 204800, 204800, 204800]
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 4]: Send buffers of size [204800, 204800, 204800, 204800, 204800, 204800, 204800, 204800]
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 4]: Receive buffers of size [204800, 204800, 204800, 204800, 204800, 204800, 204800, 204800]
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 7]: Created send and receive buffers for all_to_all halo exchange:
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 7]: Send buffers of size [204800, 204800, 204800, 204800, 204800, 204800, 204800, 204800]
[2024-07-02 13:57:45,968][__main__][INFO] - [RANK 7]: Receive buffers of size [204800, 204800, 204800, 204800, 204800, 204800, 204800, 204800]
[2024-07-02 13:57:46,002][__main__][INFO] - Done with build_model
/lus/eagle/projects/datascience/balin/Nek/GNN/env/gnn/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
/lus/eagle/projects/datascience/balin/Nek/GNN/env/gnn/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
[2024-07-02 13:57:46,016][__main__][INFO] - In writeGraphStatistics
[2024-07-02 13:57:46,016][__main__][INFO] - [RANK 0] -- model save header : POLY_5_RANK_0_SIZE_8_SEED_12_3_4_8_3_2_4_all_to_all
[2024-07-02 13:57:46,016][__main__][INFO] - [RANK 1] -- model save header : POLY_5_RANK_1_SIZE_8_SEED_12_3_4_8_3_2_4_all_to_all
/lus/eagle/projects/datascience/balin/Nek/GNN/env/gnn/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
/lus/eagle/projects/datascience/balin/Nek/GNN/env/gnn/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
[2024-07-02 13:57:46,016][__main__][INFO] - [RANK 2] -- model save header : POLY_5_RANK_2_SIZE_8_SEED_12_3_4_8_3_2_4_all_to_all
[2024-07-02 13:57:46,016][__main__][INFO] - [RANK 4] -- model save header : POLY_5_RANK_4_SIZE_8_SEED_12_3_4_8_3_2_4_all_to_all
[2024-07-02 13:57:46,016][__main__][INFO] - [RANK 3] -- model save header : POLY_5_RANK_3_SIZE_8_SEED_12_3_4_8_3_2_4_all_to_all
/lus/eagle/projects/datascience/balin/Nek/GNN/env/gnn/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
/lus/eagle/projects/datascience/balin/Nek/GNN/env/gnn/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
[2024-07-02 13:57:46,016][__main__][INFO] - [RANK 6] -- model save header : POLY_5_RANK_6_SIZE_8_SEED_12_3_4_8_3_2_4_all_to_all
/lus/eagle/projects/datascience/balin/Nek/GNN/env/gnn/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
[2024-07-02 13:57:46,016][__main__][INFO] - [RANK 7] -- model save header : POLY_5_RANK_7_SIZE_8_SEED_12_3_4_8_3_2_4_all_to_all
[2024-07-02 13:57:46,016][__main__][INFO] - [RANK 5] -- model save header : POLY_5_RANK_5_SIZE_8_SEED_12_3_4_8_3_2_4_all_to_all
/lus/eagle/projects/datascience/balin/Nek/GNN/env/gnn/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn("The verbose parameter is deprecated. Please use get_last_lr() "
Directory created by root processor.
[2024-07-02 13:57:46,018][__main__][INFO] - [RANK 0] -- number of local nodes: 518400, number of halo nodes: 12800, number of edges: 3097600
[2024-07-02 13:57:46,018][__main__][INFO] - [RANK 4] -- number of local nodes: 518400, number of halo nodes: 12800, number of edges: 3097600
[2024-07-02 13:57:46,018][__main__][INFO] - [RANK 5] -- number of local nodes: 518400, number of halo nodes: 12800, number of edges: 3097600
[2024-07-02 13:57:46,018][__main__][INFO] - [RANK 1] -- number of local nodes: 518400, number of halo nodes: 12800, number of edges: 3097600
[2024-07-02 13:57:46,018][__main__][INFO] - [RANK 6] -- number of local nodes: 518400, number of halo nodes: 12800, number of edges: 3097600
[2024-07-02 13:57:46,018][__main__][INFO] - [RANK 2] -- number of local nodes: 518400, number of halo nodes: 12800, number of edges: 3097600
[2024-07-02 13:57:46,018][__main__][INFO] - [RANK 7] -- number of local nodes: 518400, number of halo nodes: 12800, number of edges: 3097600
[2024-07-02 13:57:46,018][__main__][INFO] - [RANK 3] -- number of local nodes: 518400, number of halo nodes: 12800, number of edges: 3097600
[2024-07-02 13:57:47,350][__main__][INFO] - [0] [1/50: Batch 1 (100%)] epoch=1.0000 time[s]=1.3096 batch_loss=0.1112 running_loss=0.1112
[2024-07-02 13:57:47,381][__main__][INFO] - ----------------------
[2024-07-02 13:57:47,381][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:47,381][__main__][INFO] - ----------------------
[2024-07-02 13:57:47,381][__main__][INFO] - ---------------------------------------------
[2024-07-02 13:57:47,381][__main__][INFO] - [TRAIN]  loss=1.1118e-01  epoch_time=1.33 sec
[2024-07-02 13:57:47,381][__main__][INFO] - ---------------------------------------------
[2024-07-02 13:57:47,733][__main__][INFO] - [0] [2/50: Batch 1 (100%)] epoch=2.0000 time[s]=0.3340 batch_loss=0.1103 running_loss=0.1103
[2024-07-02 13:57:47,755][__main__][INFO] - ----------------------
[2024-07-02 13:57:47,756][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:47,756][__main__][INFO] - ----------------------
[2024-07-02 13:57:47,756][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:47,756][__main__][INFO] - [TRAIN]  loss=1.1029e-01  epoch_time=0.3526 sec
[2024-07-02 13:57:47,756][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:48,117][__main__][INFO] - [0] [3/50: Batch 1 (100%)] epoch=3.0000 time[s]=0.3425 batch_loss=0.1094 running_loss=0.1094
[2024-07-02 13:57:48,139][__main__][INFO] - ----------------------
[2024-07-02 13:57:48,139][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:48,139][__main__][INFO] - ----------------------
[2024-07-02 13:57:48,139][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:48,139][__main__][INFO] - [TRAIN]  loss=1.0941e-01  epoch_time=0.3619 sec
[2024-07-02 13:57:48,139][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:48,485][__main__][INFO] - [0] [4/50: Batch 1 (100%)] epoch=4.0000 time[s]=0.3273 batch_loss=0.1085 running_loss=0.1085
[2024-07-02 13:57:48,506][__main__][INFO] - ----------------------
[2024-07-02 13:57:48,506][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:48,506][__main__][INFO] - ----------------------
[2024-07-02 13:57:48,506][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:48,506][__main__][INFO] - [TRAIN]  loss=1.0853e-01  epoch_time=0.3466 sec
[2024-07-02 13:57:48,506][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:48,873][__main__][INFO] - [0] [5/50: Batch 1 (100%)] epoch=5.0000 time[s]=0.3485 batch_loss=0.1077 running_loss=0.1077
[2024-07-02 13:57:48,893][__main__][INFO] - ----------------------
[2024-07-02 13:57:48,894][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:48,894][__main__][INFO] - ----------------------
[2024-07-02 13:57:48,894][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:48,894][__main__][INFO] - [TRAIN]  loss=1.0766e-01  epoch_time=0.3678 sec
[2024-07-02 13:57:48,894][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:49,245][__main__][INFO] - [0] [6/50: Batch 1 (100%)] epoch=6.0000 time[s]=0.3329 batch_loss=0.1068 running_loss=0.1068
[2024-07-02 13:57:49,277][__main__][INFO] - ----------------------
[2024-07-02 13:57:49,277][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:49,277][__main__][INFO] - ----------------------
[2024-07-02 13:57:49,277][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:49,277][__main__][INFO] - [TRAIN]  loss=1.0680e-01  epoch_time=0.3519 sec
[2024-07-02 13:57:49,277][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:49,637][__main__][INFO] - [0] [7/50: Batch 1 (100%)] epoch=7.0000 time[s]=0.3410 batch_loss=0.1060 running_loss=0.1060
[2024-07-02 13:57:49,669][__main__][INFO] - ----------------------
[2024-07-02 13:57:49,669][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:49,669][__main__][INFO] - ----------------------
[2024-07-02 13:57:49,669][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:49,669][__main__][INFO] - [TRAIN]  loss=1.0597e-01  epoch_time=0.3603 sec
[2024-07-02 13:57:49,669][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:50,021][__main__][INFO] - [0] [8/50: Batch 1 (100%)] epoch=8.0000 time[s]=0.3326 batch_loss=0.1052 running_loss=0.1052
[2024-07-02 13:57:50,053][__main__][INFO] - ----------------------
[2024-07-02 13:57:50,053][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:50,053][__main__][INFO] - ----------------------
[2024-07-02 13:57:50,053][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:50,053][__main__][INFO] - [TRAIN]  loss=1.0516e-01  epoch_time=0.3524 sec
[2024-07-02 13:57:50,053][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:50,421][__main__][INFO] - [0] [9/50: Batch 1 (100%)] epoch=9.0000 time[s]=0.3489 batch_loss=0.1044 running_loss=0.1044
[2024-07-02 13:57:50,446][__main__][INFO] - ----------------------
[2024-07-02 13:57:50,446][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:50,446][__main__][INFO] - ----------------------
[2024-07-02 13:57:50,446][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:50,446][__main__][INFO] - [TRAIN]  loss=1.0437e-01  epoch_time=0.3679 sec
[2024-07-02 13:57:50,446][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:50,809][__main__][INFO] - [0] [10/50: Batch 1 (100%)] epoch=10.0000 time[s]=0.3441 batch_loss=0.1036 running_loss=0.1036
[2024-07-02 13:57:50,841][__main__][INFO] - ----------------------
[2024-07-02 13:57:50,841][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:50,841][__main__][INFO] - ----------------------
[2024-07-02 13:57:50,841][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:50,841][__main__][INFO] - [TRAIN]  loss=1.0360e-01  epoch_time=0.3634 sec
[2024-07-02 13:57:50,841][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:51,189][__main__][INFO] - [0] [11/50: Batch 1 (100%)] epoch=11.0000 time[s]=0.3283 batch_loss=0.1029 running_loss=0.1029
[2024-07-02 13:57:51,210][__main__][INFO] - ----------------------
[2024-07-02 13:57:51,210][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:51,210][__main__][INFO] - ----------------------
[2024-07-02 13:57:51,210][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:51,210][__main__][INFO] - [TRAIN]  loss=1.0286e-01  epoch_time=0.3486 sec
[2024-07-02 13:57:51,210][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:51,565][__main__][INFO] - [0] [12/50: Batch 1 (100%)] epoch=12.0000 time[s]=0.3364 batch_loss=0.1021 running_loss=0.1021
[2024-07-02 13:57:51,586][__main__][INFO] - ----------------------
[2024-07-02 13:57:51,586][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:51,586][__main__][INFO] - ----------------------
[2024-07-02 13:57:51,586][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:51,586][__main__][INFO] - [TRAIN]  loss=1.0214e-01  epoch_time=0.3558 sec
[2024-07-02 13:57:51,586][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:51,977][__main__][INFO] - [0] [13/50: Batch 1 (100%)] epoch=13.0000 time[s]=0.3722 batch_loss=0.1014 running_loss=0.1014
[2024-07-02 13:57:51,998][__main__][INFO] - ----------------------
[2024-07-02 13:57:51,998][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:51,998][__main__][INFO] - ----------------------
[2024-07-02 13:57:51,998][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:51,998][__main__][INFO] - [TRAIN]  loss=1.0144e-01  epoch_time=0.3915 sec
[2024-07-02 13:57:51,998][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:52,345][__main__][INFO] - [0] [14/50: Batch 1 (100%)] epoch=14.0000 time[s]=0.3280 batch_loss=0.1008 running_loss=0.1008
[2024-07-02 13:57:52,377][__main__][INFO] - ----------------------
[2024-07-02 13:57:52,377][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:52,377][__main__][INFO] - ----------------------
[2024-07-02 13:57:52,377][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:52,377][__main__][INFO] - [TRAIN]  loss=1.0076e-01  epoch_time=0.3475 sec
[2024-07-02 13:57:52,377][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:52,781][__main__][INFO] - [0] [15/50: Batch 1 (100%)] epoch=15.0000 time[s]=0.3850 batch_loss=0.1001 running_loss=0.1001
[2024-07-02 13:57:52,802][__main__][INFO] - ----------------------
[2024-07-02 13:57:52,802][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:52,803][__main__][INFO] - ----------------------
[2024-07-02 13:57:52,803][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:52,803][__main__][INFO] - [TRAIN]  loss=1.0011e-01  epoch_time=0.4041 sec
[2024-07-02 13:57:52,803][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:53,157][__main__][INFO] - [0] [16/50: Batch 1 (100%)] epoch=16.0000 time[s]=0.3352 batch_loss=0.0995 running_loss=0.0995
[2024-07-02 13:57:53,177][__main__][INFO] - ----------------------
[2024-07-02 13:57:53,178][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:53,178][__main__][INFO] - ----------------------
[2024-07-02 13:57:53,178][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:53,178][__main__][INFO] - [TRAIN]  loss=9.9478e-02  epoch_time=0.3548 sec
[2024-07-02 13:57:53,178][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:53,533][__main__][INFO] - [0] [17/50: Batch 1 (100%)] epoch=17.0000 time[s]=0.3368 batch_loss=0.0989 running_loss=0.0989
[2024-07-02 13:57:53,565][__main__][INFO] - ----------------------
[2024-07-02 13:57:53,565][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:53,565][__main__][INFO] - ----------------------
[2024-07-02 13:57:53,565][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:53,565][__main__][INFO] - [TRAIN]  loss=9.8873e-02  epoch_time=0.3559 sec
[2024-07-02 13:57:53,565][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:53,925][__main__][INFO] - [0] [18/50: Batch 1 (100%)] epoch=18.0000 time[s]=0.3413 batch_loss=0.0983 running_loss=0.0983
[2024-07-02 13:57:53,952][__main__][INFO] - ----------------------
[2024-07-02 13:57:53,952][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:53,952][__main__][INFO] - ----------------------
[2024-07-02 13:57:53,952][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:53,952][__main__][INFO] - [TRAIN]  loss=9.8290e-02  epoch_time=0.3605 sec
[2024-07-02 13:57:53,952][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:54,297][__main__][INFO] - [0] [19/50: Batch 1 (100%)] epoch=19.0000 time[s]=0.3263 batch_loss=0.0977 running_loss=0.0977
[2024-07-02 13:57:54,337][__main__][INFO] - ----------------------
[2024-07-02 13:57:54,337][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:54,337][__main__][INFO] - ----------------------
[2024-07-02 13:57:54,337][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:54,337][__main__][INFO] - [TRAIN]  loss=9.7730e-02  epoch_time=0.3651 sec
[2024-07-02 13:57:54,337][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:54,697][__main__][INFO] - [0] [20/50: Batch 1 (100%)] epoch=20.0000 time[s]=0.3411 batch_loss=0.0972 running_loss=0.0972
[2024-07-02 13:57:54,719][__main__][INFO] - ----------------------
[2024-07-02 13:57:54,719][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:54,719][__main__][INFO] - ----------------------
[2024-07-02 13:57:54,719][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:54,719][__main__][INFO] - [TRAIN]  loss=9.7192e-02  epoch_time=0.3604 sec
[2024-07-02 13:57:54,719][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:55,069][__main__][INFO] - [0] [21/50: Batch 1 (100%)] epoch=21.0000 time[s]=0.3310 batch_loss=0.0967 running_loss=0.0967
[2024-07-02 13:57:55,101][__main__][INFO] - ----------------------
[2024-07-02 13:57:55,101][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:55,101][__main__][INFO] - ----------------------
[2024-07-02 13:57:55,101][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:55,101][__main__][INFO] - [TRAIN]  loss=9.6674e-02  epoch_time=0.3502 sec
[2024-07-02 13:57:55,101][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:55,481][__main__][INFO] - [0] [22/50: Batch 1 (100%)] epoch=22.0000 time[s]=0.3609 batch_loss=0.0962 running_loss=0.0962
[2024-07-02 13:57:55,513][__main__][INFO] - ----------------------
[2024-07-02 13:57:55,513][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:55,513][__main__][INFO] - ----------------------
[2024-07-02 13:57:55,513][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:55,513][__main__][INFO] - [TRAIN]  loss=9.6177e-02  epoch_time=0.3804 sec
[2024-07-02 13:57:55,513][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:55,877][__main__][INFO] - [0] [23/50: Batch 1 (100%)] epoch=23.0000 time[s]=0.3454 batch_loss=0.0957 running_loss=0.0957
[2024-07-02 13:57:55,898][__main__][INFO] - ----------------------
[2024-07-02 13:57:55,898][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:55,898][__main__][INFO] - ----------------------
[2024-07-02 13:57:55,898][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:55,898][__main__][INFO] - [TRAIN]  loss=9.5697e-02  epoch_time=0.3643 sec
[2024-07-02 13:57:55,899][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:56,246][__main__][INFO] - [0] [24/50: Batch 1 (100%)] epoch=24.0000 time[s]=0.3278 batch_loss=0.0952 running_loss=0.0952
[2024-07-02 13:57:56,281][__main__][INFO] - ----------------------
[2024-07-02 13:57:56,281][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:56,281][__main__][INFO] - ----------------------
[2024-07-02 13:57:56,281][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:56,281][__main__][INFO] - [TRAIN]  loss=9.5235e-02  epoch_time=0.3472 sec
[2024-07-02 13:57:56,281][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:56,641][__main__][INFO] - [0] [25/50: Batch 1 (100%)] epoch=25.0000 time[s]=0.3410 batch_loss=0.0948 running_loss=0.0948
[2024-07-02 13:57:56,664][__main__][INFO] - ----------------------
[2024-07-02 13:57:56,664][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:56,664][__main__][INFO] - ----------------------
[2024-07-02 13:57:56,664][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:56,664][__main__][INFO] - [TRAIN]  loss=9.4790e-02  epoch_time=0.3603 sec
[2024-07-02 13:57:56,664][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:57,017][__main__][INFO] - [0] [26/50: Batch 1 (100%)] epoch=26.0000 time[s]=0.3275 batch_loss=0.0944 running_loss=0.0944
[2024-07-02 13:57:57,049][__main__][INFO] - ----------------------
[2024-07-02 13:57:57,049][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:57,049][__main__][INFO] - ----------------------
[2024-07-02 13:57:57,049][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:57,049][__main__][INFO] - [TRAIN]  loss=9.4359e-02  epoch_time=0.3538 sec
[2024-07-02 13:57:57,049][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:57,405][__main__][INFO] - [0] [27/50: Batch 1 (100%)] epoch=27.0000 time[s]=0.3371 batch_loss=0.0939 running_loss=0.0939
[2024-07-02 13:57:57,425][__main__][INFO] - ----------------------
[2024-07-02 13:57:57,426][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:57,426][__main__][INFO] - ----------------------
[2024-07-02 13:57:57,426][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:57,426][__main__][INFO] - [TRAIN]  loss=9.3944e-02  epoch_time=0.3563 sec
[2024-07-02 13:57:57,426][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:57,773][__main__][INFO] - [0] [28/50: Batch 1 (100%)] epoch=28.0000 time[s]=0.3290 batch_loss=0.0935 running_loss=0.0935
[2024-07-02 13:57:57,793][__main__][INFO] - ----------------------
[2024-07-02 13:57:57,794][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:57,794][__main__][INFO] - ----------------------
[2024-07-02 13:57:57,794][__main__][INFO] - ----------------------------------------------
[2024-07-02 13:57:57,794][__main__][INFO] - [TRAIN]  loss=9.3543e-02  epoch_time=0.348 sec
[2024-07-02 13:57:57,794][__main__][INFO] - ----------------------------------------------
[2024-07-02 13:57:58,150][__main__][INFO] - [0] [29/50: Batch 1 (100%)] epoch=29.0000 time[s]=0.3369 batch_loss=0.0932 running_loss=0.0932
[2024-07-02 13:57:58,181][__main__][INFO] - ----------------------
[2024-07-02 13:57:58,181][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:58,181][__main__][INFO] - ----------------------
[2024-07-02 13:57:58,181][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:58,181][__main__][INFO] - [TRAIN]  loss=9.3155e-02  epoch_time=0.3559 sec
[2024-07-02 13:57:58,181][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:58,541][__main__][INFO] - [0] [30/50: Batch 1 (100%)] epoch=30.0000 time[s]=0.3413 batch_loss=0.0928 running_loss=0.0928
[2024-07-02 13:57:58,562][__main__][INFO] - ----------------------
[2024-07-02 13:57:58,562][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:58,562][__main__][INFO] - ----------------------
[2024-07-02 13:57:58,562][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:58,562][__main__][INFO] - [TRAIN]  loss=9.2778e-02  epoch_time=0.3603 sec
[2024-07-02 13:57:58,562][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:58,925][__main__][INFO] - [0] [31/50: Batch 1 (100%)] epoch=31.0000 time[s]=0.3445 batch_loss=0.0924 running_loss=0.0924
[2024-07-02 13:57:58,951][__main__][INFO] - ----------------------
[2024-07-02 13:57:58,951][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:58,951][__main__][INFO] - ----------------------
[2024-07-02 13:57:58,951][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:58,951][__main__][INFO] - [TRAIN]  loss=9.2413e-02  epoch_time=0.3637 sec
[2024-07-02 13:57:58,951][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:59,313][__main__][INFO] - [0] [32/50: Batch 1 (100%)] epoch=32.0000 time[s]=0.3426 batch_loss=0.0921 running_loss=0.0921
[2024-07-02 13:57:59,345][__main__][INFO] - ----------------------
[2024-07-02 13:57:59,345][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:59,345][__main__][INFO] - ----------------------
[2024-07-02 13:57:59,345][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:59,345][__main__][INFO] - [TRAIN]  loss=9.2057e-02  epoch_time=0.3627 sec
[2024-07-02 13:57:59,345][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:59,701][__main__][INFO] - [0] [33/50: Batch 1 (100%)] epoch=33.0000 time[s]=0.3376 batch_loss=0.0917 running_loss=0.0917
[2024-07-02 13:57:59,721][__main__][INFO] - ----------------------
[2024-07-02 13:57:59,722][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:57:59,722][__main__][INFO] - ----------------------
[2024-07-02 13:57:59,722][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:57:59,722][__main__][INFO] - [TRAIN]  loss=9.1709e-02  epoch_time=0.3563 sec
[2024-07-02 13:57:59,722][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:00,073][__main__][INFO] - [0] [34/50: Batch 1 (100%)] epoch=34.0000 time[s]=0.3326 batch_loss=0.0914 running_loss=0.0914
[2024-07-02 13:58:00,108][__main__][INFO] - ----------------------
[2024-07-02 13:58:00,108][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:58:00,108][__main__][INFO] - ----------------------
[2024-07-02 13:58:00,108][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:00,108][__main__][INFO] - [TRAIN]  loss=9.1369e-02  epoch_time=0.3519 sec
[2024-07-02 13:58:00,108][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:00,477][__main__][INFO] - [0] [35/50: Batch 1 (100%)] epoch=35.0000 time[s]=0.3503 batch_loss=0.0910 running_loss=0.0910
[2024-07-02 13:58:00,512][__main__][INFO] - ----------------------
[2024-07-02 13:58:00,513][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:58:00,513][__main__][INFO] - ----------------------
[2024-07-02 13:58:00,513][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:00,513][__main__][INFO] - [TRAIN]  loss=9.1037e-02  epoch_time=0.3692 sec
[2024-07-02 13:58:00,513][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:00,865][__main__][INFO] - [0] [36/50: Batch 1 (100%)] epoch=36.0000 time[s]=0.3335 batch_loss=0.0907 running_loss=0.0907
[2024-07-02 13:58:00,886][__main__][INFO] - ----------------------
[2024-07-02 13:58:00,886][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:58:00,886][__main__][INFO] - ----------------------
[2024-07-02 13:58:00,886][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:00,886][__main__][INFO] - [TRAIN]  loss=9.0710e-02  epoch_time=0.3527 sec
[2024-07-02 13:58:00,886][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:01,241][__main__][INFO] - [0] [37/50: Batch 1 (100%)] epoch=37.0000 time[s]=0.3368 batch_loss=0.0904 running_loss=0.0904
[2024-07-02 13:58:01,262][__main__][INFO] - ----------------------
[2024-07-02 13:58:01,262][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:58:01,262][__main__][INFO] - ----------------------
[2024-07-02 13:58:01,262][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:01,262][__main__][INFO] - [TRAIN]  loss=9.0390e-02  epoch_time=0.3557 sec
[2024-07-02 13:58:01,262][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:01,607][__main__][INFO] - [0] [38/50: Batch 1 (100%)] epoch=38.0000 time[s]=0.3270 batch_loss=0.0901 running_loss=0.0901
[2024-07-02 13:58:01,637][__main__][INFO] - ----------------------
[2024-07-02 13:58:01,637][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:58:01,637][__main__][INFO] - ----------------------
[2024-07-02 13:58:01,637][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:01,637][__main__][INFO] - [TRAIN]  loss=9.0075e-02  epoch_time=0.3458 sec
[2024-07-02 13:58:01,637][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:01,989][__main__][INFO] - [0] [39/50: Batch 1 (100%)] epoch=39.0000 time[s]=0.3332 batch_loss=0.0898 running_loss=0.0898
[2024-07-02 13:58:02,017][__main__][INFO] - ----------------------
[2024-07-02 13:58:02,018][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:58:02,018][__main__][INFO] - ----------------------
[2024-07-02 13:58:02,018][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:02,018][__main__][INFO] - [TRAIN]  loss=8.9766e-02  epoch_time=0.3523 sec
[2024-07-02 13:58:02,018][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:02,401][__main__][INFO] - [0] [40/50: Batch 1 (100%)] epoch=40.0000 time[s]=0.3648 batch_loss=0.0895 running_loss=0.0895
[2024-07-02 13:58:02,422][__main__][INFO] - ----------------------
[2024-07-02 13:58:02,422][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:58:02,422][__main__][INFO] - ----------------------
[2024-07-02 13:58:02,422][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:02,422][__main__][INFO] - [TRAIN]  loss=8.9462e-02  epoch_time=0.3839 sec
[2024-07-02 13:58:02,422][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:02,771][__main__][INFO] - [0] [41/50: Batch 1 (100%)] epoch=41.0000 time[s]=0.3295 batch_loss=0.0892 running_loss=0.0892
[2024-07-02 13:58:02,791][__main__][INFO] - ----------------------
[2024-07-02 13:58:02,791][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:58:02,791][__main__][INFO] - ----------------------
[2024-07-02 13:58:02,791][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:02,791][__main__][INFO] - [TRAIN]  loss=8.9163e-02  epoch_time=0.3489 sec
[2024-07-02 13:58:02,791][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:03,146][__main__][INFO] - [0] [42/50: Batch 1 (100%)] epoch=42.0000 time[s]=0.3343 batch_loss=0.0889 running_loss=0.0889
[2024-07-02 13:58:03,166][__main__][INFO] - ----------------------
[2024-07-02 13:58:03,166][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:58:03,166][__main__][INFO] - ----------------------
[2024-07-02 13:58:03,166][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:03,166][__main__][INFO] - [TRAIN]  loss=8.8869e-02  epoch_time=0.3546 sec
[2024-07-02 13:58:03,166][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:03,529][__main__][INFO] - [0] [43/50: Batch 1 (100%)] epoch=43.0000 time[s]=0.3445 batch_loss=0.0886 running_loss=0.0886
[2024-07-02 13:58:03,558][__main__][INFO] - ----------------------
[2024-07-02 13:58:03,558][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:58:03,558][__main__][INFO] - ----------------------
[2024-07-02 13:58:03,558][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:03,558][__main__][INFO] - [TRAIN]  loss=8.8580e-02  epoch_time=0.3636 sec
[2024-07-02 13:58:03,558][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:03,937][__main__][INFO] - [0] [44/50: Batch 1 (100%)] epoch=44.0000 time[s]=0.3604 batch_loss=0.0883 running_loss=0.0883
[2024-07-02 13:58:03,958][__main__][INFO] - ----------------------
[2024-07-02 13:58:03,958][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:58:03,958][__main__][INFO] - ----------------------
[2024-07-02 13:58:03,958][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:03,959][__main__][INFO] - [TRAIN]  loss=8.8297e-02  epoch_time=0.3798 sec
[2024-07-02 13:58:03,959][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:04,317][__main__][INFO] - [0] [45/50: Batch 1 (100%)] epoch=45.0000 time[s]=0.3393 batch_loss=0.0880 running_loss=0.0880
[2024-07-02 13:58:04,338][__main__][INFO] - ----------------------
[2024-07-02 13:58:04,338][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:58:04,338][__main__][INFO] - ----------------------
[2024-07-02 13:58:04,338][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:04,338][__main__][INFO] - [TRAIN]  loss=8.8018e-02  epoch_time=0.3592 sec
[2024-07-02 13:58:04,338][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:04,689][__main__][INFO] - [0] [46/50: Batch 1 (100%)] epoch=46.0000 time[s]=0.3326 batch_loss=0.0877 running_loss=0.0877
[2024-07-02 13:58:04,721][__main__][INFO] - ----------------------
[2024-07-02 13:58:04,721][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:58:04,721][__main__][INFO] - ----------------------
[2024-07-02 13:58:04,721][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:04,721][__main__][INFO] - [TRAIN]  loss=8.7745e-02  epoch_time=0.3517 sec
[2024-07-02 13:58:04,721][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:05,073][__main__][INFO] - [0] [47/50: Batch 1 (100%)] epoch=47.0000 time[s]=0.3334 batch_loss=0.0875 running_loss=0.0875
[2024-07-02 13:58:05,094][__main__][INFO] - ----------------------
[2024-07-02 13:58:05,094][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:58:05,094][__main__][INFO] - ----------------------
[2024-07-02 13:58:05,094][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:05,094][__main__][INFO] - [TRAIN]  loss=8.7477e-02  epoch_time=0.3527 sec
[2024-07-02 13:58:05,094][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:05,449][__main__][INFO] - [0] [48/50: Batch 1 (100%)] epoch=48.0000 time[s]=0.3366 batch_loss=0.0872 running_loss=0.0872
[2024-07-02 13:58:05,469][__main__][INFO] - ----------------------
[2024-07-02 13:58:05,470][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:58:05,470][__main__][INFO] - ----------------------
[2024-07-02 13:58:05,470][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:05,470][__main__][INFO] - [TRAIN]  loss=8.7215e-02  epoch_time=0.3558 sec
[2024-07-02 13:58:05,470][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:05,833][__main__][INFO] - [0] [49/50: Batch 1 (100%)] epoch=49.0000 time[s]=0.3452 batch_loss=0.0870 running_loss=0.0870
[2024-07-02 13:58:05,871][__main__][INFO] - ----------------------
[2024-07-02 13:58:05,871][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:58:05,871][__main__][INFO] - ----------------------
[2024-07-02 13:58:05,871][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:05,871][__main__][INFO] - [TRAIN]  loss=8.6959e-02  epoch_time=0.3639 sec
[2024-07-02 13:58:05,871][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:06,245][__main__][INFO] - [0] [50/50: Batch 1 (100%)] epoch=50.0000 time[s]=0.3553 batch_loss=0.0867 running_loss=0.0867
[2024-07-02 13:58:06,277][__main__][INFO] - ----------------------
[2024-07-02 13:58:06,277][__main__][INFO] - [4] :: Total training time: 31.142632722854614 seconds
[2024-07-02 13:58:06,277][__main__][INFO] - [TEST] loss=0.0000e+00
[2024-07-02 13:58:06,277][__main__][INFO] - ----------------------
[2024-07-02 13:58:06,277][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:06,277][__main__][INFO] - [TRAIN]  loss=8.6709e-02  epoch_time=0.3744 sec
[2024-07-02 13:58:06,277][__main__][INFO] - -----------------------------------------------
[2024-07-02 13:58:06,277][__main__][INFO] - [5] :: Total training time: 30.62229871749878 seconds
[2024-07-02 13:58:06,277][__main__][INFO] - [1] :: Total training time: 31.747735738754272 seconds
[2024-07-02 13:58:06,277][__main__][INFO] - [6] :: Total training time: 30.624308586120605 seconds
[2024-07-02 13:58:06,277][__main__][INFO] - [7] :: Total training time: 30.622129678726196 seconds
[2024-07-02 13:58:06,277][__main__][INFO] - [2] :: Total training time: 31.747455835342407 seconds
[2024-07-02 13:58:06,277][__main__][INFO] - [3] :: Total training time: 31.74728512763977 seconds
[2024-07-02 13:58:06,278][__main__][INFO] - [0] :: Total training time: 32.29820466041565 seconds

Summary of performance data:
Total training time: 32.29820466041565
Training epoch [s] : min = 3.453813e-01 , max = 4.045649e-01 , avg = 3.604775e-01 , std = 1.164223e-02 
Training throughput [nodes/s] : min = 1.281377e+06 , max = 1.500950e+06 , avg = 1.439523e+06 , std = 4.435769e+04 
Average parallel training throughout [nodes/s] : 1.151619e+07
Training batch [s] : min = 3.250742e-01 , max = 3.856552e-01 , avg = 3.405658e-01 , std = 1.162012e-02 
forwardPass [s] : min = 7.601929e-02 , max = 1.065192e-01 , avg = 8.120601e-02 , std = 6.928275e-03 
backwardPass [s] : min = 1.545057e-01 , max = 2.010350e-01 , avg = 1.676669e-01 , std = 7.745926e-03 
loss [s] : min = 4.019737e-04 , max = 5.550623e-03 , avg = 1.437409e-03 , std = 1.780085e-03 
optimizerStep [s] : min = 1.081944e-03 , max = 2.207279e-03 , avg = 1.130856e-03 , std = 1.353493e-04 
dataTransfer [s] : min = 9.867907e-03 , max = 1.075602e-02 , avg = 1.023883e-02 , std = 1.785148e-04 
bufferInit [s] : min = 2.005100e-04 , max = 2.648830e-04 , avg = 2.188780e-04 , std = 8.463357e-06 
Tue 02 Jul 2024 01:58:08 PM UTC
